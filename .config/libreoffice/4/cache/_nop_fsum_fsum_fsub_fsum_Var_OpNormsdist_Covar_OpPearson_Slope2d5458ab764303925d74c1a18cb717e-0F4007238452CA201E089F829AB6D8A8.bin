//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-25773113
// Unknown Toolkit Version
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_75, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope

.entry DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9
)
{
	.reg .pred 	%p<182>;
	.reg .f32 	%f<13>;
	.reg .b32 	%r<360>;
	.reg .f64 	%fd<1839>;
	.reg .b64 	%rd<69>;


	ld.param.u64 	%rd9, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4];
	ld.param.u64 	%rd10, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5];
	ld.param.u64 	%rd11, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6];
	ld.param.u64 	%rd12, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7];
	ld.param.u64 	%rd13, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8];
	ld.param.u64 	%rd14, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9];
	mov.b32	%r145, %envreg3;
	mov.u32 	%r146, %ctaid.x;
	mov.u32 	%r147, %ntid.x;
	mad.lo.s32 	%r1, %r146, %r147, %r145;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	mov.f64 	%fd1759, 0d0000000000000000;
	setp.gt.s32	%p1, %r3, 5;
	mov.f64 	%fd1758, %fd1759;
	mov.f64 	%fd1757, %fd1759;
	@%p1 bra 	BB0_6;

	add.s32 	%r316, %r1, %r2;
	mov.f64 	%fd1759, 0d0000000000000000;
	mov.u32 	%r315, 1;
	mov.f64 	%fd1758, %fd1759;
	mov.f64 	%fd1757, %fd1759;

BB0_2:
	mul.wide.s32 	%rd15, %r316, 8;
	add.s64 	%rd16, %rd14, %rd15;
	add.s64 	%rd17, %rd13, %rd15;
	ld.global.f64 	%fd4, [%rd17];
	ld.global.f64 	%fd5, [%rd16];
	abs.f64 	%fd259, %fd5;
	setp.gtu.f64	%p2, %fd259, 0d7FF0000000000000;
	@%p2 bra 	BB0_5;

	abs.f64 	%fd260, %fd4;
	setp.gtu.f64	%p3, %fd260, 0d7FF0000000000000;
	@%p3 bra 	BB0_5;

	add.f64 	%fd1759, %fd1759, %fd5;
	add.f64 	%fd1758, %fd1758, %fd4;
	add.f64 	%fd1757, %fd1757, 0d3FF0000000000000;

BB0_5:
	add.s32 	%r316, %r316, 1;
	setp.lt.s32	%p4, %r316, 6;
	setp.lt.s32	%p5, %r315, 2;
	and.pred  	%p6, %p4, %p5;
	add.s32 	%r315, %r315, 1;
	@%p6 bra 	BB0_2;

BB0_6:
	setp.lt.f64	%p7, %fd1757, 0d3FF0000000000000;
	mov.f64 	%fd1779, 0dFFF8000000000000;
	@%p7 bra 	BB0_65;

	setp.eq.f64	%p8, %fd1757, 0d3FF0000000000000;
	mov.f64 	%fd1767, 0d3FF0000000000000;
	@%p8 bra 	BB0_33;

	abs.f64 	%fd15, %fd1757;
	setp.gtu.f64	%p9, %fd15, 0d7FF0000000000000;
	@%p9 bra 	BB0_32;
	bra.uni 	BB0_9;

BB0_32:
	add.f64 	%fd1767, %fd1757, 0dBFF0000000000000;
	bra.uni 	BB0_33;

BB0_9:
	setp.eq.f64	%p10, %fd1757, 0d7FF0000000000000;
	@%p10 bra 	BB0_31;
	bra.uni 	BB0_10;

BB0_31:
	mov.f64 	%fd453, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd453;
	}
	setp.gt.s32	%p27, %r169, -1;
	selp.f64	%fd1767, 0d7FF0000000000000, 0d0000000000000000, %p27;
	bra.uni 	BB0_33;

BB0_10:
	mov.f64 	%fd263, 0dBFF0000000000000;
	mov.f64 	%fd264, 0d3FE0000000000000;
	mul.rn.f64 	%fd265, %fd264, %fd263;
	cvt.rzi.f64.f64	%fd266, %fd265;
	mov.f64 	%fd267, 0d4000000000000000;
	mul.rn.f64 	%fd268, %fd267, %fd266;
	sub.f64 	%fd269, %fd263, %fd268;
	abs.f64 	%fd16, %fd269;
	setp.eq.f64	%p11, %fd1757, 0d0000000000000000;
	@%p11 bra 	BB0_30;
	bra.uni 	BB0_11;

BB0_30:
	setp.eq.f64	%p26, %fd16, 0d3FF0000000000000;
	rcp.rn.f64 	%fd450, %fd1757;
	mov.f64 	%fd451, 0d0000000000000000;
	rcp.rn.f64 	%fd452, %fd451;
	selp.f64	%fd1767, %fd450, %fd452, %p26;
	bra.uni 	BB0_33;

BB0_11:
	setp.eq.f64	%p12, %fd1757, 0dFFF0000000000000;
	@%p12 bra 	BB0_28;
	bra.uni 	BB0_12;

BB0_28:
	div.rn.f64 	%fd1767, %fd263, %fd1757;
	setp.neu.f64	%p25, %fd16, 0d3FF0000000000000;
	@%p25 bra 	BB0_33;

	mov.b64 	 %rd20, %fd1767;
	xor.b64  	%rd21, %rd20, -9223372036854775808;
	mov.b64 	 %fd1767, %rd21;
	bra.uni 	BB0_33;

BB0_12:
	setp.geu.f64	%p13, %fd1757, 0d0000000000000000;
	@%p13 bra 	BB0_14;

	cvt.rzi.f64.f64	%fd272, %fd263;
	setp.neu.f64	%p14, %fd272, 0dBFF0000000000000;
	mov.f64 	%fd1767, 0dFFF8000000000000;
	@%p14 bra 	BB0_33;

BB0_14:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r318}, %fd15; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r317, hi}, %fd15; 
	}
	// inline asm
	bfe.u32 	%r319, %r318, 20, 11;
	setp.ne.s32	%p15, %r319, 0;
	@%p15 bra 	BB0_16;

	mov.f64 	%fd277, 0d4350000000000000;
	mul.rn.f64 	%fd276, %fd15, %fd277;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r318}, %fd276; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r317, hi}, %fd276; 
	}
	// inline asm
	bfe.u32 	%r153, %r318, 20, 11;
	add.s32 	%r319, %r153, -54;

BB0_16:
	and.b32  	%r156, %r318, -2146435073;
	or.b32  	%r155, %r156, 1072693248;
	// inline asm
	mov.b64 	%fd1763, {%r317, %r155};
	// inline asm
	add.s32 	%r320, %r319, -1023;
	setp.lt.u32	%p16, %r155, 1073127583;
	@%p16 bra 	BB0_18;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r157, hi}, %fd1763; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r158}, %fd1763; 
	}
	// inline asm
	add.s32 	%r160, %r158, -1048576;
	// inline asm
	mov.b64 	%fd1763, {%r157, %r160};
	// inline asm
	add.s32 	%r320, %r319, -1022;

BB0_18:
	add.f64 	%fd366, %fd1763, 0d3FF0000000000000;
	rcp.rn.f64 	%fd367, %fd366;
	add.f64 	%fd308, %fd1763, 0dBFF0000000000000;
	mul.rn.f64 	%fd368, %fd308, %fd367;
	add.f64 	%fd356, %fd368, %fd368;
	mul.rn.f64 	%fd304, %fd356, %fd356;
	mov.f64 	%fd283, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd285, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd282, %fd283, %fd304, %fd285;
	// inline asm
	mov.f64 	%fd289, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd286, %fd282, %fd304, %fd289;
	// inline asm
	mov.f64 	%fd293, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd290, %fd286, %fd304, %fd293;
	// inline asm
	mov.f64 	%fd297, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd294, %fd290, %fd304, %fd297;
	// inline asm
	mov.f64 	%fd301, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd298, %fd294, %fd304, %fd301;
	// inline asm
	mov.f64 	%fd305, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd302, %fd298, %fd304, %fd305;
	// inline asm
	mul.rn.f64 	%fd369, %fd302, %fd304;
	sub.f64 	%fd370, %fd308, %fd356;
	mul.rn.f64 	%fd309, %fd267, %fd370;
	neg.f64 	%fd307, %fd356;
	// inline asm
	fma.rn.f64 	%fd306, %fd307, %fd308, %fd309;
	// inline asm
	mul.rn.f64 	%fd352, %fd367, %fd306;
	add.f64 	%fd372, %fd369, 0d3FB5555555555555;
	mov.f64 	%fd373, 0d3FB5555555555555;
	sub.f64 	%fd374, %fd373, %fd372;
	add.f64 	%fd375, %fd369, %fd374;
	add.f64 	%fd376, %fd375, 0d0000000000000000;
	add.f64 	%fd377, %fd376, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd319, %fd372, %fd377;
	sub.f64 	%fd378, %fd372, %fd319;
	add.f64 	%fd323, %fd377, %fd378;
	mul.rn.f64 	%fd379, %fd319, %fd356;
	neg.f64 	%fd313, %fd379;
	// inline asm
	fma.rn.f64 	%fd310, %fd319, %fd356, %fd313;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd314, %fd323, %fd352, %fd310;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd318, %fd319, %fd352, %fd314;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd322, %fd323, %fd356, %fd318;
	// inline asm
	add.f64 	%fd335, %fd379, %fd322;
	sub.f64 	%fd380, %fd379, %fd335;
	add.f64 	%fd339, %fd322, %fd380;
	mul.rn.f64 	%fd381, %fd335, %fd356;
	neg.f64 	%fd329, %fd381;
	// inline asm
	fma.rn.f64 	%fd326, %fd335, %fd356, %fd329;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd330, %fd339, %fd352, %fd326;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd334, %fd335, %fd352, %fd330;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd338, %fd339, %fd356, %fd334;
	// inline asm
	add.f64 	%fd351, %fd381, %fd338;
	sub.f64 	%fd382, %fd381, %fd351;
	add.f64 	%fd355, %fd338, %fd382;
	mul.rn.f64 	%fd383, %fd351, %fd356;
	neg.f64 	%fd345, %fd383;
	// inline asm
	fma.rn.f64 	%fd342, %fd351, %fd356, %fd345;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd346, %fd355, %fd352, %fd342;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd350, %fd351, %fd352, %fd346;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd354, %fd355, %fd356, %fd350;
	// inline asm
	add.f64 	%fd384, %fd383, %fd354;
	sub.f64 	%fd385, %fd383, %fd384;
	add.f64 	%fd386, %fd354, %fd385;
	add.f64 	%fd387, %fd356, %fd384;
	sub.f64 	%fd388, %fd356, %fd387;
	add.f64 	%fd389, %fd384, %fd388;
	add.f64 	%fd390, %fd386, %fd389;
	add.f64 	%fd391, %fd352, %fd390;
	add.f64 	%fd392, %fd387, %fd391;
	sub.f64 	%fd393, %fd387, %fd392;
	add.f64 	%fd394, %fd391, %fd393;
	cvt.rn.f64.s32	%fd395, %r320;
	mov.f64 	%fd396, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd397, %fd395, %fd396;
	mov.f64 	%fd398, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd399, %fd395, %fd398;
	add.f64 	%fd400, %fd397, %fd392;
	sub.f64 	%fd401, %fd397, %fd400;
	add.f64 	%fd402, %fd392, %fd401;
	add.f64 	%fd403, %fd394, %fd402;
	add.f64 	%fd404, %fd399, %fd403;
	add.f64 	%fd359, %fd400, %fd404;
	sub.f64 	%fd405, %fd400, %fd359;
	add.f64 	%fd363, %fd404, %fd405;
	mul.rn.f64 	%fd406, %fd359, %fd263;
	neg.f64 	%fd361, %fd406;
	// inline asm
	fma.rn.f64 	%fd358, %fd359, %fd263, %fd361;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd362, %fd363, %fd263, %fd358;
	// inline asm
	add.f64 	%fd20, %fd406, %fd362;
	sub.f64 	%fd407, %fd406, %fd20;
	add.f64 	%fd21, %fd362, %fd407;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd20;
	}
	mov.b32 	 %f1, %r21;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p17, %f2, 0f40874911;
	@%p17 bra 	BB0_20;
	bra.uni 	BB0_19;

BB0_20:
	mov.f64 	%fd411, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd412, %fd20, %fd411;
	mov.f64 	%fd413, 0d4338000000000000;
	add.rn.f64 	%fd414, %fd412, %fd413;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd414;
	}
	mov.f64 	%fd415, 0dC338000000000000;
	add.rn.f64 	%fd416, %fd414, %fd415;
	mov.f64 	%fd417, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd418, %fd416, %fd417, %fd20;
	mov.f64 	%fd419, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd420, %fd416, %fd419, %fd418;
	mov.f64 	%fd421, 0d3E928AF3FCA213EA;
	mov.f64 	%fd422, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd423, %fd422, %fd420, %fd421;
	mov.f64 	%fd424, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd425, %fd423, %fd420, %fd424;
	mov.f64 	%fd426, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd427, %fd425, %fd420, %fd426;
	mov.f64 	%fd428, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd429, %fd427, %fd420, %fd428;
	mov.f64 	%fd430, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd431, %fd429, %fd420, %fd430;
	mov.f64 	%fd432, 0d3F81111111122322;
	fma.rn.f64 	%fd433, %fd431, %fd420, %fd432;
	mov.f64 	%fd434, 0d3FA55555555502A1;
	fma.rn.f64 	%fd435, %fd433, %fd420, %fd434;
	mov.f64 	%fd436, 0d3FC5555555555511;
	fma.rn.f64 	%fd437, %fd435, %fd420, %fd436;
	mov.f64 	%fd438, 0d3FE000000000000B;
	fma.rn.f64 	%fd439, %fd437, %fd420, %fd438;
	mov.f64 	%fd440, 0d3FF0000000000000;
	fma.rn.f64 	%fd441, %fd439, %fd420, %fd440;
	fma.rn.f64 	%fd1764, %fd441, %fd420, %fd440;
	abs.s32 	%r161, %r22;
	setp.lt.s32	%p20, %r161, 1023;
	@%p20 bra 	BB0_22;
	bra.uni 	BB0_21;

BB0_22:
	shl.b32 	%r167, %r22, 20;
	add.s32 	%r321, %r167, 1072693248;
	bra.uni 	BB0_23;

BB0_19:
	setp.lt.s32	%p18, %r21, 0;
	selp.f64	%fd408, 0d0000000000000000, 0d7FF0000000000000, %p18;
	abs.f64 	%fd409, %fd20;
	setp.gtu.f64	%p19, %fd409, 0d7FF0000000000000;
	add.f64 	%fd410, %fd20, %fd20;
	selp.f64	%fd1767, %fd410, %fd408, %p19;
	bra.uni 	BB0_24;

BB0_21:
	add.s32 	%r162, %r22, 2046;
	shl.b32 	%r163, %r162, 19;
	and.b32  	%r164, %r163, -1048576;
	shl.b32 	%r165, %r162, 20;
	sub.s32 	%r321, %r165, %r164;
	mov.u32 	%r166, 0;
	mov.b64 	%fd442, {%r166, %r164};
	mul.f64 	%fd1764, %fd1764, %fd442;

BB0_23:
	mov.u32 	%r168, 0;
	mov.b64 	%fd443, {%r168, %r321};
	mul.f64 	%fd1767, %fd1764, %fd443;

BB0_24:
	abs.f64 	%fd444, %fd1767;
	setp.eq.f64	%p21, %fd444, 0d7FF0000000000000;
	@%p21 bra 	BB0_26;

	// inline asm
	fma.rn.f64 	%fd1767, %fd1767, %fd21, %fd1767;
	// inline asm

BB0_26:
	setp.neu.f64	%p22, %fd16, 0d3FF0000000000000;
	or.pred  	%p24, %p13, %p22;
	@%p24 bra 	BB0_33;

	mov.b64 	 %rd18, %fd1767;
	xor.b64  	%rd19, %rd18, -9223372036854775808;
	mov.b64 	 %fd1767, %rd19;

BB0_33:
	mul.f64 	%fd37, %fd1759, %fd1767;
	mul.f64 	%fd38, %fd1758, %fd1767;
	mov.f64 	%fd1771, 0d0000000000000000;
	mov.f64 	%fd1770, %fd1771;
	@%p1 bra 	BB0_39;

	mov.f64 	%fd1771, 0d0000000000000000;
	mov.u32 	%r322, 1;
	mov.u32 	%r323, %r3;
	mov.f64 	%fd1770, %fd1771;

BB0_35:
	mul.wide.s32 	%rd22, %r323, 8;
	add.s64 	%rd23, %rd14, %rd22;
	add.s64 	%rd24, %rd13, %rd22;
	ld.global.f64 	%fd41, [%rd24];
	ld.global.f64 	%fd42, [%rd23];
	abs.f64 	%fd458, %fd42;
	setp.gtu.f64	%p29, %fd458, 0d7FF0000000000000;
	@%p29 bra 	BB0_38;

	abs.f64 	%fd459, %fd41;
	setp.gtu.f64	%p30, %fd459, 0d7FF0000000000000;
	@%p30 bra 	BB0_38;

	sub.f64 	%fd460, %fd42, %fd37;
	sub.f64 	%fd461, %fd41, %fd38;
	fma.rn.f64 	%fd1771, %fd460, %fd461, %fd1771;
	fma.rn.f64 	%fd1770, %fd460, %fd460, %fd1770;

BB0_38:
	add.s32 	%r323, %r323, 1;
	setp.lt.s32	%p31, %r323, 6;
	setp.lt.s32	%p32, %r322, 2;
	and.pred  	%p33, %p31, %p32;
	add.s32 	%r322, %r322, 1;
	@%p33 bra 	BB0_35;

BB0_39:
	mov.f64 	%fd1779, 0dFFF8000000000000;
	setp.eq.f64	%p34, %fd1770, 0d0000000000000000;
	@%p34 bra 	BB0_65;

	setp.eq.f64	%p35, %fd1770, 0d3FF0000000000000;
	mov.f64 	%fd1778, 0d3FF0000000000000;
	@%p35 bra 	BB0_64;

	abs.f64 	%fd49, %fd1770;
	setp.gtu.f64	%p36, %fd49, 0d7FF0000000000000;
	@%p36 bra 	BB0_63;
	bra.uni 	BB0_42;

BB0_63:
	add.f64 	%fd1778, %fd1770, 0dBFF0000000000000;
	bra.uni 	BB0_64;

BB0_42:
	setp.eq.f64	%p37, %fd1770, 0d7FF0000000000000;
	@%p37 bra 	BB0_62;
	bra.uni 	BB0_43;

BB0_62:
	mov.f64 	%fd651, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r191}, %fd651;
	}
	setp.gt.s32	%p52, %r191, -1;
	selp.f64	%fd1778, 0d7FF0000000000000, 0d0000000000000000, %p52;
	bra.uni 	BB0_64;

BB0_43:
	mov.f64 	%fd464, 0dBFF0000000000000;
	mov.f64 	%fd465, 0d3FE0000000000000;
	mul.rn.f64 	%fd466, %fd465, %fd464;
	cvt.rzi.f64.f64	%fd467, %fd466;
	mov.f64 	%fd468, 0d4000000000000000;
	mul.rn.f64 	%fd469, %fd468, %fd467;
	sub.f64 	%fd470, %fd464, %fd469;
	abs.f64 	%fd50, %fd470;
	setp.eq.f64	%p38, %fd1770, 0dFFF0000000000000;
	@%p38 bra 	BB0_60;
	bra.uni 	BB0_44;

BB0_60:
	div.rn.f64 	%fd1778, %fd464, %fd1770;
	setp.neu.f64	%p51, %fd50, 0d3FF0000000000000;
	@%p51 bra 	BB0_64;

	mov.b64 	 %rd27, %fd1778;
	xor.b64  	%rd28, %rd27, -9223372036854775808;
	mov.b64 	 %fd1778, %rd28;
	bra.uni 	BB0_64;

BB0_44:
	setp.geu.f64	%p39, %fd1770, 0d0000000000000000;
	@%p39 bra 	BB0_46;

	cvt.rzi.f64.f64	%fd473, %fd464;
	setp.neu.f64	%p40, %fd473, 0dBFF0000000000000;
	mov.f64 	%fd1778, 0dFFF8000000000000;
	@%p40 bra 	BB0_64;

BB0_46:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r325}, %fd49; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r324, hi}, %fd49; 
	}
	// inline asm
	bfe.u32 	%r326, %r325, 20, 11;
	setp.ne.s32	%p41, %r326, 0;
	@%p41 bra 	BB0_48;

	mov.f64 	%fd478, 0d4350000000000000;
	mul.rn.f64 	%fd477, %fd49, %fd478;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r325}, %fd477; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r324, hi}, %fd477; 
	}
	// inline asm
	bfe.u32 	%r175, %r325, 20, 11;
	add.s32 	%r326, %r175, -54;

BB0_48:
	and.b32  	%r178, %r325, -2146435073;
	or.b32  	%r177, %r178, 1072693248;
	// inline asm
	mov.b64 	%fd1774, {%r324, %r177};
	// inline asm
	add.s32 	%r327, %r326, -1023;
	setp.lt.u32	%p42, %r177, 1073127583;
	@%p42 bra 	BB0_50;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r179, hi}, %fd1774; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r180}, %fd1774; 
	}
	// inline asm
	add.s32 	%r182, %r180, -1048576;
	// inline asm
	mov.b64 	%fd1774, {%r179, %r182};
	// inline asm
	add.s32 	%r327, %r326, -1022;

BB0_50:
	add.f64 	%fd567, %fd1774, 0d3FF0000000000000;
	rcp.rn.f64 	%fd568, %fd567;
	add.f64 	%fd509, %fd1774, 0dBFF0000000000000;
	mul.rn.f64 	%fd569, %fd509, %fd568;
	add.f64 	%fd557, %fd569, %fd569;
	mul.rn.f64 	%fd505, %fd557, %fd557;
	mov.f64 	%fd484, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd486, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd483, %fd484, %fd505, %fd486;
	// inline asm
	mov.f64 	%fd490, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd487, %fd483, %fd505, %fd490;
	// inline asm
	mov.f64 	%fd494, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd491, %fd487, %fd505, %fd494;
	// inline asm
	mov.f64 	%fd498, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd495, %fd491, %fd505, %fd498;
	// inline asm
	mov.f64 	%fd502, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd499, %fd495, %fd505, %fd502;
	// inline asm
	mov.f64 	%fd506, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd503, %fd499, %fd505, %fd506;
	// inline asm
	mul.rn.f64 	%fd570, %fd503, %fd505;
	sub.f64 	%fd571, %fd509, %fd557;
	mul.rn.f64 	%fd510, %fd468, %fd571;
	neg.f64 	%fd508, %fd557;
	// inline asm
	fma.rn.f64 	%fd507, %fd508, %fd509, %fd510;
	// inline asm
	mul.rn.f64 	%fd553, %fd568, %fd507;
	add.f64 	%fd573, %fd570, 0d3FB5555555555555;
	mov.f64 	%fd574, 0d3FB5555555555555;
	sub.f64 	%fd575, %fd574, %fd573;
	add.f64 	%fd576, %fd570, %fd575;
	add.f64 	%fd577, %fd576, 0d0000000000000000;
	add.f64 	%fd578, %fd577, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd520, %fd573, %fd578;
	sub.f64 	%fd579, %fd573, %fd520;
	add.f64 	%fd524, %fd578, %fd579;
	mul.rn.f64 	%fd580, %fd520, %fd557;
	neg.f64 	%fd514, %fd580;
	// inline asm
	fma.rn.f64 	%fd511, %fd520, %fd557, %fd514;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd515, %fd524, %fd553, %fd511;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd519, %fd520, %fd553, %fd515;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd523, %fd524, %fd557, %fd519;
	// inline asm
	add.f64 	%fd536, %fd580, %fd523;
	sub.f64 	%fd581, %fd580, %fd536;
	add.f64 	%fd540, %fd523, %fd581;
	mul.rn.f64 	%fd582, %fd536, %fd557;
	neg.f64 	%fd530, %fd582;
	// inline asm
	fma.rn.f64 	%fd527, %fd536, %fd557, %fd530;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd531, %fd540, %fd553, %fd527;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd535, %fd536, %fd553, %fd531;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd539, %fd540, %fd557, %fd535;
	// inline asm
	add.f64 	%fd552, %fd582, %fd539;
	sub.f64 	%fd583, %fd582, %fd552;
	add.f64 	%fd556, %fd539, %fd583;
	mul.rn.f64 	%fd584, %fd552, %fd557;
	neg.f64 	%fd546, %fd584;
	// inline asm
	fma.rn.f64 	%fd543, %fd552, %fd557, %fd546;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd547, %fd556, %fd553, %fd543;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd551, %fd552, %fd553, %fd547;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd555, %fd556, %fd557, %fd551;
	// inline asm
	add.f64 	%fd585, %fd584, %fd555;
	sub.f64 	%fd586, %fd584, %fd585;
	add.f64 	%fd587, %fd555, %fd586;
	add.f64 	%fd588, %fd557, %fd585;
	sub.f64 	%fd589, %fd557, %fd588;
	add.f64 	%fd590, %fd585, %fd589;
	add.f64 	%fd591, %fd587, %fd590;
	add.f64 	%fd592, %fd553, %fd591;
	add.f64 	%fd593, %fd588, %fd592;
	sub.f64 	%fd594, %fd588, %fd593;
	add.f64 	%fd595, %fd592, %fd594;
	cvt.rn.f64.s32	%fd596, %r327;
	mov.f64 	%fd597, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd598, %fd596, %fd597;
	mov.f64 	%fd599, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd600, %fd596, %fd599;
	add.f64 	%fd601, %fd598, %fd593;
	sub.f64 	%fd602, %fd598, %fd601;
	add.f64 	%fd603, %fd593, %fd602;
	add.f64 	%fd604, %fd595, %fd603;
	add.f64 	%fd605, %fd600, %fd604;
	add.f64 	%fd560, %fd601, %fd605;
	sub.f64 	%fd606, %fd601, %fd560;
	add.f64 	%fd564, %fd605, %fd606;
	mul.rn.f64 	%fd607, %fd560, %fd464;
	neg.f64 	%fd562, %fd607;
	// inline asm
	fma.rn.f64 	%fd559, %fd560, %fd464, %fd562;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd563, %fd564, %fd464, %fd559;
	// inline asm
	add.f64 	%fd54, %fd607, %fd563;
	sub.f64 	%fd608, %fd607, %fd54;
	add.f64 	%fd55, %fd563, %fd608;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd54;
	}
	mov.b32 	 %f3, %r43;
	abs.f32 	%f4, %f3;
	setp.lt.f32	%p43, %f4, 0f40874911;
	@%p43 bra 	BB0_52;
	bra.uni 	BB0_51;

BB0_52:
	mov.f64 	%fd612, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd613, %fd54, %fd612;
	mov.f64 	%fd614, 0d4338000000000000;
	add.rn.f64 	%fd615, %fd613, %fd614;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd615;
	}
	mov.f64 	%fd616, 0dC338000000000000;
	add.rn.f64 	%fd617, %fd615, %fd616;
	mov.f64 	%fd618, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd619, %fd617, %fd618, %fd54;
	mov.f64 	%fd620, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd621, %fd617, %fd620, %fd619;
	mov.f64 	%fd622, 0d3E928AF3FCA213EA;
	mov.f64 	%fd623, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd624, %fd623, %fd621, %fd622;
	mov.f64 	%fd625, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd626, %fd624, %fd621, %fd625;
	mov.f64 	%fd627, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd628, %fd626, %fd621, %fd627;
	mov.f64 	%fd629, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd630, %fd628, %fd621, %fd629;
	mov.f64 	%fd631, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd632, %fd630, %fd621, %fd631;
	mov.f64 	%fd633, 0d3F81111111122322;
	fma.rn.f64 	%fd634, %fd632, %fd621, %fd633;
	mov.f64 	%fd635, 0d3FA55555555502A1;
	fma.rn.f64 	%fd636, %fd634, %fd621, %fd635;
	mov.f64 	%fd637, 0d3FC5555555555511;
	fma.rn.f64 	%fd638, %fd636, %fd621, %fd637;
	mov.f64 	%fd639, 0d3FE000000000000B;
	fma.rn.f64 	%fd640, %fd638, %fd621, %fd639;
	mov.f64 	%fd641, 0d3FF0000000000000;
	fma.rn.f64 	%fd642, %fd640, %fd621, %fd641;
	fma.rn.f64 	%fd1775, %fd642, %fd621, %fd641;
	abs.s32 	%r183, %r44;
	setp.lt.s32	%p46, %r183, 1023;
	@%p46 bra 	BB0_54;
	bra.uni 	BB0_53;

BB0_54:
	shl.b32 	%r189, %r44, 20;
	add.s32 	%r328, %r189, 1072693248;
	bra.uni 	BB0_55;

BB0_51:
	setp.lt.s32	%p44, %r43, 0;
	selp.f64	%fd609, 0d0000000000000000, 0d7FF0000000000000, %p44;
	abs.f64 	%fd610, %fd54;
	setp.gtu.f64	%p45, %fd610, 0d7FF0000000000000;
	add.f64 	%fd611, %fd54, %fd54;
	selp.f64	%fd1778, %fd611, %fd609, %p45;
	bra.uni 	BB0_56;

BB0_53:
	add.s32 	%r184, %r44, 2046;
	shl.b32 	%r185, %r184, 19;
	and.b32  	%r186, %r185, -1048576;
	shl.b32 	%r187, %r184, 20;
	sub.s32 	%r328, %r187, %r186;
	mov.u32 	%r188, 0;
	mov.b64 	%fd643, {%r188, %r186};
	mul.f64 	%fd1775, %fd1775, %fd643;

BB0_55:
	mov.u32 	%r190, 0;
	mov.b64 	%fd644, {%r190, %r328};
	mul.f64 	%fd1778, %fd1775, %fd644;

BB0_56:
	abs.f64 	%fd645, %fd1778;
	setp.eq.f64	%p47, %fd645, 0d7FF0000000000000;
	@%p47 bra 	BB0_58;

	// inline asm
	fma.rn.f64 	%fd1778, %fd1778, %fd55, %fd1778;
	// inline asm

BB0_58:
	setp.neu.f64	%p48, %fd50, 0d3FF0000000000000;
	or.pred  	%p50, %p39, %p48;
	@%p50 bra 	BB0_64;

	mov.b64 	 %rd25, %fd1778;
	xor.b64  	%rd26, %rd25, -9223372036854775808;
	mov.b64 	 %fd1778, %rd26;

BB0_64:
	fma.rn.f64 	%fd1779, %fd1771, %fd1778, 0d0000000000000000;

BB0_65:
	mov.f64 	%fd1804, 0d0000000000000000;
	mov.f64 	%fd1780, %fd1804;
	mov.f64 	%fd1787, %fd1804;
	mov.f64 	%fd1788, %fd1804;
	@%p1 bra 	BB0_71;

	mov.u32 	%r314, %tid.x;
	add.s32 	%r330, %r1, %r314;
	mov.f64 	%fd1780, 0d0000000000000000;
	mov.u32 	%r329, 1;
	mov.f64 	%fd1787, %fd1780;
	mov.f64 	%fd1788, %fd1780;

BB0_67:
	mul.wide.s32 	%rd29, %r330, 8;
	add.s64 	%rd30, %rd11, %rd29;
	add.s64 	%rd31, %rd12, %rd29;
	ld.global.f64 	%fd1785, [%rd31];
	ld.global.f64 	%fd1783, [%rd30];
	abs.f64 	%fd658, %fd1783;
	setp.gtu.f64	%p54, %fd658, 0d7FF0000000000000;
	@%p54 bra 	BB0_69;

	abs.f64 	%fd659, %fd1785;
	setp.le.f64	%p55, %fd659, 0d7FF0000000000000;
	@%p55 bra 	BB0_70;

BB0_69:
	add.f64 	%fd1780, %fd1780, 0dBFF0000000000000;
	mov.f64 	%fd1783, 0d0000000000000000;
	mov.f64 	%fd1785, %fd1783;

BB0_70:
	add.f64 	%fd1787, %fd1787, %fd1783;
	add.f64 	%fd1788, %fd1788, %fd1785;
	add.f64 	%fd1780, %fd1780, 0d3FF0000000000000;
	add.s32 	%r330, %r330, 1;
	setp.lt.s32	%p56, %r330, 6;
	setp.lt.s32	%p57, %r329, 2;
	and.pred  	%p58, %p56, %p57;
	add.s32 	%r329, %r329, 1;
	@%p58 bra 	BB0_67;

BB0_71:
	div.rn.f64 	%fd87, %fd1787, %fd1780;
	div.rn.f64 	%fd88, %fd1788, %fd1780;
	mov.f64 	%fd1805, %fd1804;
	mov.f64 	%fd1806, %fd1804;
	@%p1 bra 	BB0_129;

	mov.u32 	%r313, %tid.x;
	add.s32 	%r332, %r1, %r313;
	mov.f64 	%fd1804, 0d0000000000000000;
	mov.u32 	%r331, 1;
	mov.f64 	%fd1805, %fd1804;
	mov.f64 	%fd1806, %fd1804;

BB0_73:
	mul.wide.s32 	%rd32, %r332, 8;
	add.s64 	%rd33, %rd11, %rd32;
	add.s64 	%rd34, %rd12, %rd32;
	ld.global.f64 	%fd1793, [%rd34];
	ld.global.f64 	%fd1792, [%rd33];
	abs.f64 	%fd668, %fd1792;
	setp.gtu.f64	%p60, %fd668, 0d7FF0000000000000;
	@%p60 bra 	BB0_75;

	abs.f64 	%fd669, %fd1793;
	setp.le.f64	%p61, %fd669, 0d7FF0000000000000;
	@%p61 bra 	BB0_76;

BB0_75:
	mov.f64 	%fd1792, 0d0000000000000000;
	mov.f64 	%fd1793, %fd1792;

BB0_76:
	sub.f64 	%fd96, %fd1793, %fd88;
	sub.f64 	%fd97, %fd1792, %fd87;
	fma.rn.f64 	%fd1806, %fd97, %fd96, %fd1806;
	setp.eq.f64	%p62, %fd97, 0d3FF0000000000000;
	mov.f64 	%fd1803, 0d3FF0000000000000;
	mov.f64 	%fd1798, %fd1803;
	@%p62 bra 	BB0_102;

	abs.f64 	%fd99, %fd97;
	setp.gtu.f64	%p63, %fd99, 0d7FF0000000000000;
	@%p63 bra 	BB0_101;
	bra.uni 	BB0_78;

BB0_101:
	add.f64 	%fd1798, %fd97, 0d4000000000000000;
	bra.uni 	BB0_102;

BB0_78:
	setp.eq.f64	%p64, %fd97, 0d7FF0000000000000;
	@%p64 bra 	BB0_100;
	bra.uni 	BB0_79;

BB0_100:
	mov.f64 	%fd857, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd857;
	}
	setp.gt.s32	%p81, %r214, -1;
	selp.f64	%fd1798, 0d7FF0000000000000, 0d0000000000000000, %p81;
	bra.uni 	BB0_102;

BB0_79:
	mov.f64 	%fd673, 0d4000000000000000;
	mov.f64 	%fd674, 0d3FE0000000000000;
	mul.rn.f64 	%fd675, %fd674, %fd673;
	cvt.rzi.f64.f64	%fd676, %fd675;
	mul.rn.f64 	%fd677, %fd673, %fd676;
	sub.f64 	%fd678, %fd673, %fd677;
	abs.f64 	%fd100, %fd678;
	setp.eq.f64	%p65, %fd97, 0d0000000000000000;
	@%p65 bra 	BB0_99;
	bra.uni 	BB0_80;

BB0_99:
	setp.eq.f64	%p80, %fd100, 0d3FF0000000000000;
	selp.f64	%fd1798, %fd97, 0d0000000000000000, %p80;
	bra.uni 	BB0_102;

BB0_80:
	setp.eq.f64	%p66, %fd97, 0dFFF0000000000000;
	@%p66 bra 	BB0_97;
	bra.uni 	BB0_81;

BB0_97:
	neg.f64 	%fd1798, %fd97;
	setp.neu.f64	%p79, %fd100, 0d3FF0000000000000;
	@%p79 bra 	BB0_102;

	mov.b64 	 %rd37, %fd1798;
	xor.b64  	%rd38, %rd37, -9223372036854775808;
	mov.b64 	 %fd1798, %rd38;
	bra.uni 	BB0_102;

BB0_81:
	setp.geu.f64	%p67, %fd97, 0d0000000000000000;
	@%p67 bra 	BB0_83;

	cvt.rzi.f64.f64	%fd681, %fd673;
	setp.neu.f64	%p68, %fd681, 0d4000000000000000;
	mov.f64 	%fd1798, 0dFFF8000000000000;
	@%p68 bra 	BB0_102;

BB0_83:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r334}, %fd99; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r333, hi}, %fd99; 
	}
	// inline asm
	bfe.u32 	%r335, %r334, 20, 11;
	setp.ne.s32	%p69, %r335, 0;
	@%p69 bra 	BB0_85;

	mov.f64 	%fd686, 0d4350000000000000;
	mul.rn.f64 	%fd685, %fd99, %fd686;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r334}, %fd685; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r333, hi}, %fd685; 
	}
	// inline asm
	bfe.u32 	%r198, %r334, 20, 11;
	add.s32 	%r335, %r198, -54;

BB0_85:
	and.b32  	%r201, %r334, -2146435073;
	or.b32  	%r200, %r201, 1072693248;
	// inline asm
	mov.b64 	%fd1794, {%r333, %r200};
	// inline asm
	add.s32 	%r336, %r335, -1023;
	setp.lt.u32	%p70, %r200, 1073127583;
	@%p70 bra 	BB0_87;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r202, hi}, %fd1794; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r203}, %fd1794; 
	}
	// inline asm
	add.s32 	%r205, %r203, -1048576;
	// inline asm
	mov.b64 	%fd1794, {%r202, %r205};
	// inline asm
	add.s32 	%r336, %r335, -1022;

BB0_87:
	add.f64 	%fd775, %fd1794, 0d3FF0000000000000;
	rcp.rn.f64 	%fd776, %fd775;
	add.f64 	%fd717, %fd1794, 0dBFF0000000000000;
	mul.rn.f64 	%fd777, %fd717, %fd776;
	add.f64 	%fd765, %fd777, %fd777;
	mul.rn.f64 	%fd713, %fd765, %fd765;
	mov.f64 	%fd692, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd694, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd691, %fd692, %fd713, %fd694;
	// inline asm
	mov.f64 	%fd698, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd695, %fd691, %fd713, %fd698;
	// inline asm
	mov.f64 	%fd702, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd699, %fd695, %fd713, %fd702;
	// inline asm
	mov.f64 	%fd706, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd703, %fd699, %fd713, %fd706;
	// inline asm
	mov.f64 	%fd710, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd707, %fd703, %fd713, %fd710;
	// inline asm
	mov.f64 	%fd714, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd711, %fd707, %fd713, %fd714;
	// inline asm
	mul.rn.f64 	%fd778, %fd711, %fd713;
	sub.f64 	%fd779, %fd717, %fd765;
	mul.rn.f64 	%fd718, %fd673, %fd779;
	neg.f64 	%fd716, %fd765;
	// inline asm
	fma.rn.f64 	%fd715, %fd716, %fd717, %fd718;
	// inline asm
	mul.rn.f64 	%fd761, %fd776, %fd715;
	add.f64 	%fd780, %fd778, 0d3FB5555555555555;
	mov.f64 	%fd781, 0d3FB5555555555555;
	sub.f64 	%fd782, %fd781, %fd780;
	add.f64 	%fd783, %fd778, %fd782;
	add.f64 	%fd784, %fd783, 0d0000000000000000;
	add.f64 	%fd785, %fd784, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd728, %fd780, %fd785;
	sub.f64 	%fd786, %fd780, %fd728;
	add.f64 	%fd732, %fd785, %fd786;
	mul.rn.f64 	%fd787, %fd728, %fd765;
	neg.f64 	%fd722, %fd787;
	// inline asm
	fma.rn.f64 	%fd719, %fd728, %fd765, %fd722;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd723, %fd732, %fd761, %fd719;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd727, %fd728, %fd761, %fd723;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd731, %fd732, %fd765, %fd727;
	// inline asm
	add.f64 	%fd744, %fd787, %fd731;
	sub.f64 	%fd788, %fd787, %fd744;
	add.f64 	%fd748, %fd731, %fd788;
	mul.rn.f64 	%fd789, %fd744, %fd765;
	neg.f64 	%fd738, %fd789;
	// inline asm
	fma.rn.f64 	%fd735, %fd744, %fd765, %fd738;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd739, %fd748, %fd761, %fd735;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd743, %fd744, %fd761, %fd739;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd747, %fd748, %fd765, %fd743;
	// inline asm
	add.f64 	%fd760, %fd789, %fd747;
	sub.f64 	%fd790, %fd789, %fd760;
	add.f64 	%fd764, %fd747, %fd790;
	mul.rn.f64 	%fd791, %fd760, %fd765;
	neg.f64 	%fd754, %fd791;
	// inline asm
	fma.rn.f64 	%fd751, %fd760, %fd765, %fd754;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd755, %fd764, %fd761, %fd751;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd759, %fd760, %fd761, %fd755;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd763, %fd764, %fd765, %fd759;
	// inline asm
	add.f64 	%fd792, %fd791, %fd763;
	sub.f64 	%fd793, %fd791, %fd792;
	add.f64 	%fd794, %fd763, %fd793;
	add.f64 	%fd795, %fd765, %fd792;
	sub.f64 	%fd796, %fd765, %fd795;
	add.f64 	%fd797, %fd792, %fd796;
	add.f64 	%fd798, %fd794, %fd797;
	add.f64 	%fd799, %fd761, %fd798;
	add.f64 	%fd800, %fd795, %fd799;
	sub.f64 	%fd801, %fd795, %fd800;
	add.f64 	%fd802, %fd799, %fd801;
	cvt.rn.f64.s32	%fd803, %r336;
	mov.f64 	%fd804, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd805, %fd803, %fd804;
	mov.f64 	%fd806, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd807, %fd803, %fd806;
	add.f64 	%fd808, %fd805, %fd800;
	sub.f64 	%fd809, %fd805, %fd808;
	add.f64 	%fd810, %fd800, %fd809;
	add.f64 	%fd811, %fd802, %fd810;
	add.f64 	%fd812, %fd807, %fd811;
	add.f64 	%fd768, %fd808, %fd812;
	sub.f64 	%fd813, %fd808, %fd768;
	add.f64 	%fd772, %fd812, %fd813;
	mul.rn.f64 	%fd814, %fd768, %fd673;
	neg.f64 	%fd770, %fd814;
	// inline asm
	fma.rn.f64 	%fd767, %fd768, %fd673, %fd770;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd771, %fd772, %fd673, %fd767;
	// inline asm
	add.f64 	%fd104, %fd814, %fd771;
	sub.f64 	%fd815, %fd814, %fd104;
	add.f64 	%fd105, %fd771, %fd815;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd104;
	}
	mov.b32 	 %f5, %r68;
	abs.f32 	%f6, %f5;
	setp.lt.f32	%p71, %f6, 0f40874911;
	@%p71 bra 	BB0_89;
	bra.uni 	BB0_88;

BB0_89:
	mov.f64 	%fd819, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd820, %fd104, %fd819;
	mov.f64 	%fd821, 0d4338000000000000;
	add.rn.f64 	%fd822, %fd820, %fd821;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd822;
	}
	mov.f64 	%fd823, 0dC338000000000000;
	add.rn.f64 	%fd824, %fd822, %fd823;
	mov.f64 	%fd825, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd826, %fd824, %fd825, %fd104;
	mov.f64 	%fd827, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd828, %fd824, %fd827, %fd826;
	mov.f64 	%fd829, 0d3E928AF3FCA213EA;
	mov.f64 	%fd830, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd831, %fd830, %fd828, %fd829;
	mov.f64 	%fd832, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd833, %fd831, %fd828, %fd832;
	mov.f64 	%fd834, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd835, %fd833, %fd828, %fd834;
	mov.f64 	%fd836, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd837, %fd835, %fd828, %fd836;
	mov.f64 	%fd838, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd839, %fd837, %fd828, %fd838;
	mov.f64 	%fd840, 0d3F81111111122322;
	fma.rn.f64 	%fd841, %fd839, %fd828, %fd840;
	mov.f64 	%fd842, 0d3FA55555555502A1;
	fma.rn.f64 	%fd843, %fd841, %fd828, %fd842;
	mov.f64 	%fd844, 0d3FC5555555555511;
	fma.rn.f64 	%fd845, %fd843, %fd828, %fd844;
	mov.f64 	%fd846, 0d3FE000000000000B;
	fma.rn.f64 	%fd847, %fd845, %fd828, %fd846;
	mov.f64 	%fd848, 0d3FF0000000000000;
	fma.rn.f64 	%fd849, %fd847, %fd828, %fd848;
	fma.rn.f64 	%fd1795, %fd849, %fd828, %fd848;
	abs.s32 	%r206, %r69;
	setp.lt.s32	%p74, %r206, 1023;
	@%p74 bra 	BB0_91;
	bra.uni 	BB0_90;

BB0_91:
	shl.b32 	%r212, %r69, 20;
	add.s32 	%r337, %r212, 1072693248;
	bra.uni 	BB0_92;

BB0_88:
	setp.lt.s32	%p72, %r68, 0;
	selp.f64	%fd816, 0d0000000000000000, 0d7FF0000000000000, %p72;
	abs.f64 	%fd817, %fd104;
	setp.gtu.f64	%p73, %fd817, 0d7FF0000000000000;
	add.f64 	%fd818, %fd104, %fd104;
	selp.f64	%fd1798, %fd818, %fd816, %p73;
	bra.uni 	BB0_93;

BB0_90:
	add.s32 	%r207, %r69, 2046;
	shl.b32 	%r208, %r207, 19;
	and.b32  	%r209, %r208, -1048576;
	shl.b32 	%r210, %r207, 20;
	sub.s32 	%r337, %r210, %r209;
	mov.u32 	%r211, 0;
	mov.b64 	%fd850, {%r211, %r209};
	mul.f64 	%fd1795, %fd1795, %fd850;

BB0_92:
	mov.u32 	%r213, 0;
	mov.b64 	%fd851, {%r213, %r337};
	mul.f64 	%fd1798, %fd1795, %fd851;

BB0_93:
	abs.f64 	%fd852, %fd1798;
	setp.eq.f64	%p75, %fd852, 0d7FF0000000000000;
	@%p75 bra 	BB0_95;

	// inline asm
	fma.rn.f64 	%fd1798, %fd1798, %fd105, %fd1798;
	// inline asm

BB0_95:
	setp.neu.f64	%p76, %fd100, 0d3FF0000000000000;
	or.pred  	%p78, %p67, %p76;
	@%p78 bra 	BB0_102;

	mov.b64 	 %rd35, %fd1798;
	xor.b64  	%rd36, %rd35, -9223372036854775808;
	mov.b64 	 %fd1798, %rd36;

BB0_102:
	add.f64 	%fd1804, %fd1804, %fd1798;
	setp.eq.f64	%p82, %fd96, 0d3FF0000000000000;
	@%p82 bra 	BB0_128;

	abs.f64 	%fd122, %fd96;
	setp.gtu.f64	%p83, %fd122, 0d7FF0000000000000;
	@%p83 bra 	BB0_127;
	bra.uni 	BB0_104;

BB0_127:
	add.f64 	%fd1803, %fd96, 0d4000000000000000;
	bra.uni 	BB0_128;

BB0_104:
	setp.eq.f64	%p84, %fd96, 0d7FF0000000000000;
	@%p84 bra 	BB0_126;
	bra.uni 	BB0_105;

BB0_126:
	mov.f64 	%fd1043, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r235}, %fd1043;
	}
	setp.gt.s32	%p101, %r235, -1;
	selp.f64	%fd1803, 0d7FF0000000000000, 0d0000000000000000, %p101;
	bra.uni 	BB0_128;

BB0_105:
	mov.f64 	%fd859, 0d4000000000000000;
	mov.f64 	%fd860, 0d3FE0000000000000;
	mul.rn.f64 	%fd861, %fd860, %fd859;
	cvt.rzi.f64.f64	%fd862, %fd861;
	mul.rn.f64 	%fd863, %fd859, %fd862;
	sub.f64 	%fd864, %fd859, %fd863;
	abs.f64 	%fd123, %fd864;
	setp.eq.f64	%p85, %fd96, 0d0000000000000000;
	@%p85 bra 	BB0_125;
	bra.uni 	BB0_106;

BB0_125:
	setp.eq.f64	%p100, %fd123, 0d3FF0000000000000;
	selp.f64	%fd1803, %fd96, 0d0000000000000000, %p100;
	bra.uni 	BB0_128;

BB0_106:
	setp.eq.f64	%p86, %fd96, 0dFFF0000000000000;
	@%p86 bra 	BB0_123;
	bra.uni 	BB0_107;

BB0_123:
	neg.f64 	%fd1803, %fd96;
	setp.neu.f64	%p99, %fd123, 0d3FF0000000000000;
	@%p99 bra 	BB0_128;

	mov.b64 	 %rd41, %fd1803;
	xor.b64  	%rd42, %rd41, -9223372036854775808;
	mov.b64 	 %fd1803, %rd42;
	bra.uni 	BB0_128;

BB0_107:
	setp.geu.f64	%p87, %fd96, 0d0000000000000000;
	@%p87 bra 	BB0_109;

	cvt.rzi.f64.f64	%fd867, %fd859;
	setp.neu.f64	%p88, %fd867, 0d4000000000000000;
	mov.f64 	%fd1803, 0dFFF8000000000000;
	@%p88 bra 	BB0_128;

BB0_109:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r339}, %fd122; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r338, hi}, %fd122; 
	}
	// inline asm
	bfe.u32 	%r340, %r339, 20, 11;
	setp.ne.s32	%p89, %r340, 0;
	@%p89 bra 	BB0_111;

	mov.f64 	%fd872, 0d4350000000000000;
	mul.rn.f64 	%fd871, %fd122, %fd872;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r339}, %fd871; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r338, hi}, %fd871; 
	}
	// inline asm
	bfe.u32 	%r219, %r339, 20, 11;
	add.s32 	%r340, %r219, -54;

BB0_111:
	and.b32  	%r222, %r339, -2146435073;
	or.b32  	%r221, %r222, 1072693248;
	// inline asm
	mov.b64 	%fd1799, {%r338, %r221};
	// inline asm
	add.s32 	%r341, %r340, -1023;
	setp.lt.u32	%p90, %r221, 1073127583;
	@%p90 bra 	BB0_113;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r223, hi}, %fd1799; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r224}, %fd1799; 
	}
	// inline asm
	add.s32 	%r226, %r224, -1048576;
	// inline asm
	mov.b64 	%fd1799, {%r223, %r226};
	// inline asm
	add.s32 	%r341, %r340, -1022;

BB0_113:
	add.f64 	%fd961, %fd1799, 0d3FF0000000000000;
	rcp.rn.f64 	%fd962, %fd961;
	add.f64 	%fd903, %fd1799, 0dBFF0000000000000;
	mul.rn.f64 	%fd963, %fd903, %fd962;
	add.f64 	%fd951, %fd963, %fd963;
	mul.rn.f64 	%fd899, %fd951, %fd951;
	mov.f64 	%fd878, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd880, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd877, %fd878, %fd899, %fd880;
	// inline asm
	mov.f64 	%fd884, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd881, %fd877, %fd899, %fd884;
	// inline asm
	mov.f64 	%fd888, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd885, %fd881, %fd899, %fd888;
	// inline asm
	mov.f64 	%fd892, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd889, %fd885, %fd899, %fd892;
	// inline asm
	mov.f64 	%fd896, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd893, %fd889, %fd899, %fd896;
	// inline asm
	mov.f64 	%fd900, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd897, %fd893, %fd899, %fd900;
	// inline asm
	mul.rn.f64 	%fd964, %fd897, %fd899;
	sub.f64 	%fd965, %fd903, %fd951;
	mul.rn.f64 	%fd904, %fd859, %fd965;
	neg.f64 	%fd902, %fd951;
	// inline asm
	fma.rn.f64 	%fd901, %fd902, %fd903, %fd904;
	// inline asm
	mul.rn.f64 	%fd947, %fd962, %fd901;
	add.f64 	%fd966, %fd964, 0d3FB5555555555555;
	mov.f64 	%fd967, 0d3FB5555555555555;
	sub.f64 	%fd968, %fd967, %fd966;
	add.f64 	%fd969, %fd964, %fd968;
	add.f64 	%fd970, %fd969, 0d0000000000000000;
	add.f64 	%fd971, %fd970, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd914, %fd966, %fd971;
	sub.f64 	%fd972, %fd966, %fd914;
	add.f64 	%fd918, %fd971, %fd972;
	mul.rn.f64 	%fd973, %fd914, %fd951;
	neg.f64 	%fd908, %fd973;
	// inline asm
	fma.rn.f64 	%fd905, %fd914, %fd951, %fd908;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd909, %fd918, %fd947, %fd905;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd913, %fd914, %fd947, %fd909;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd917, %fd918, %fd951, %fd913;
	// inline asm
	add.f64 	%fd930, %fd973, %fd917;
	sub.f64 	%fd974, %fd973, %fd930;
	add.f64 	%fd934, %fd917, %fd974;
	mul.rn.f64 	%fd975, %fd930, %fd951;
	neg.f64 	%fd924, %fd975;
	// inline asm
	fma.rn.f64 	%fd921, %fd930, %fd951, %fd924;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd925, %fd934, %fd947, %fd921;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd929, %fd930, %fd947, %fd925;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd933, %fd934, %fd951, %fd929;
	// inline asm
	add.f64 	%fd946, %fd975, %fd933;
	sub.f64 	%fd976, %fd975, %fd946;
	add.f64 	%fd950, %fd933, %fd976;
	mul.rn.f64 	%fd977, %fd946, %fd951;
	neg.f64 	%fd940, %fd977;
	// inline asm
	fma.rn.f64 	%fd937, %fd946, %fd951, %fd940;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd941, %fd950, %fd947, %fd937;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd945, %fd946, %fd947, %fd941;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd949, %fd950, %fd951, %fd945;
	// inline asm
	add.f64 	%fd978, %fd977, %fd949;
	sub.f64 	%fd979, %fd977, %fd978;
	add.f64 	%fd980, %fd949, %fd979;
	add.f64 	%fd981, %fd951, %fd978;
	sub.f64 	%fd982, %fd951, %fd981;
	add.f64 	%fd983, %fd978, %fd982;
	add.f64 	%fd984, %fd980, %fd983;
	add.f64 	%fd985, %fd947, %fd984;
	add.f64 	%fd986, %fd981, %fd985;
	sub.f64 	%fd987, %fd981, %fd986;
	add.f64 	%fd988, %fd985, %fd987;
	cvt.rn.f64.s32	%fd989, %r341;
	mov.f64 	%fd990, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd991, %fd989, %fd990;
	mov.f64 	%fd992, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd993, %fd989, %fd992;
	add.f64 	%fd994, %fd991, %fd986;
	sub.f64 	%fd995, %fd991, %fd994;
	add.f64 	%fd996, %fd986, %fd995;
	add.f64 	%fd997, %fd988, %fd996;
	add.f64 	%fd998, %fd993, %fd997;
	add.f64 	%fd954, %fd994, %fd998;
	sub.f64 	%fd999, %fd994, %fd954;
	add.f64 	%fd958, %fd998, %fd999;
	mul.rn.f64 	%fd1000, %fd954, %fd859;
	neg.f64 	%fd956, %fd1000;
	// inline asm
	fma.rn.f64 	%fd953, %fd954, %fd859, %fd956;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd957, %fd958, %fd859, %fd953;
	// inline asm
	add.f64 	%fd127, %fd1000, %fd957;
	sub.f64 	%fd1001, %fd1000, %fd127;
	add.f64 	%fd128, %fd957, %fd1001;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd127;
	}
	mov.b32 	 %f7, %r85;
	abs.f32 	%f8, %f7;
	setp.lt.f32	%p91, %f8, 0f40874911;
	@%p91 bra 	BB0_115;
	bra.uni 	BB0_114;

BB0_115:
	mov.f64 	%fd1005, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1006, %fd127, %fd1005;
	mov.f64 	%fd1007, 0d4338000000000000;
	add.rn.f64 	%fd1008, %fd1006, %fd1007;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd1008;
	}
	mov.f64 	%fd1009, 0dC338000000000000;
	add.rn.f64 	%fd1010, %fd1008, %fd1009;
	mov.f64 	%fd1011, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1012, %fd1010, %fd1011, %fd127;
	mov.f64 	%fd1013, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1014, %fd1010, %fd1013, %fd1012;
	mov.f64 	%fd1015, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1016, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1017, %fd1016, %fd1014, %fd1015;
	mov.f64 	%fd1018, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1019, %fd1017, %fd1014, %fd1018;
	mov.f64 	%fd1020, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1021, %fd1019, %fd1014, %fd1020;
	mov.f64 	%fd1022, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1023, %fd1021, %fd1014, %fd1022;
	mov.f64 	%fd1024, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1025, %fd1023, %fd1014, %fd1024;
	mov.f64 	%fd1026, 0d3F81111111122322;
	fma.rn.f64 	%fd1027, %fd1025, %fd1014, %fd1026;
	mov.f64 	%fd1028, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1029, %fd1027, %fd1014, %fd1028;
	mov.f64 	%fd1030, 0d3FC5555555555511;
	fma.rn.f64 	%fd1031, %fd1029, %fd1014, %fd1030;
	mov.f64 	%fd1032, 0d3FE000000000000B;
	fma.rn.f64 	%fd1033, %fd1031, %fd1014, %fd1032;
	mov.f64 	%fd1034, 0d3FF0000000000000;
	fma.rn.f64 	%fd1035, %fd1033, %fd1014, %fd1034;
	fma.rn.f64 	%fd1800, %fd1035, %fd1014, %fd1034;
	abs.s32 	%r227, %r86;
	setp.lt.s32	%p94, %r227, 1023;
	@%p94 bra 	BB0_117;
	bra.uni 	BB0_116;

BB0_117:
	shl.b32 	%r233, %r86, 20;
	add.s32 	%r342, %r233, 1072693248;
	bra.uni 	BB0_118;

BB0_114:
	setp.lt.s32	%p92, %r85, 0;
	selp.f64	%fd1002, 0d0000000000000000, 0d7FF0000000000000, %p92;
	abs.f64 	%fd1003, %fd127;
	setp.gtu.f64	%p93, %fd1003, 0d7FF0000000000000;
	add.f64 	%fd1004, %fd127, %fd127;
	selp.f64	%fd1803, %fd1004, %fd1002, %p93;
	bra.uni 	BB0_119;

BB0_116:
	add.s32 	%r228, %r86, 2046;
	shl.b32 	%r229, %r228, 19;
	and.b32  	%r230, %r229, -1048576;
	shl.b32 	%r231, %r228, 20;
	sub.s32 	%r342, %r231, %r230;
	mov.u32 	%r232, 0;
	mov.b64 	%fd1036, {%r232, %r230};
	mul.f64 	%fd1800, %fd1800, %fd1036;

BB0_118:
	mov.u32 	%r234, 0;
	mov.b64 	%fd1037, {%r234, %r342};
	mul.f64 	%fd1803, %fd1800, %fd1037;

BB0_119:
	abs.f64 	%fd1038, %fd1803;
	setp.eq.f64	%p95, %fd1038, 0d7FF0000000000000;
	@%p95 bra 	BB0_121;

	// inline asm
	fma.rn.f64 	%fd1803, %fd1803, %fd128, %fd1803;
	// inline asm

BB0_121:
	setp.neu.f64	%p96, %fd123, 0d3FF0000000000000;
	or.pred  	%p98, %p87, %p96;
	@%p98 bra 	BB0_128;

	mov.b64 	 %rd39, %fd1803;
	xor.b64  	%rd40, %rd39, -9223372036854775808;
	mov.b64 	 %fd1803, %rd40;

BB0_128:
	add.f64 	%fd1805, %fd1805, %fd1803;
	add.s32 	%r332, %r332, 1;
	setp.lt.s32	%p102, %r332, 6;
	setp.lt.s32	%p103, %r331, 2;
	and.pred  	%p104, %p102, %p103;
	add.s32 	%r331, %r331, 1;
	@%p104 bra 	BB0_73;

BB0_129:
	mov.f64 	%fd1811, 0d0000000000000000;
	mul.f64 	%fd1046, %fd1805, %fd1804;
	sqrt.rn.f64 	%fd1047, %fd1046;
	div.rn.f64 	%fd1048, %fd1806, %fd1047;
	abs.f64 	%fd1049, %fd1048;
	setp.gtu.f64	%p105, %fd1049, 0d7FF0000000000000;
	add.f64 	%fd1050, %fd1048, 0d0000000000000000;
	selp.f64	%fd148, 0dFFF8000000000000, %fd1050, %p105;
	mov.u32 	%r345, 0;
	mov.f64 	%fd1812, %fd1811;
	@%p1 bra 	BB0_135;

	mov.u32 	%r312, %tid.x;
	add.s32 	%r344, %r1, %r312;
	mov.f64 	%fd1811, 0d0000000000000000;
	mov.u32 	%r345, 0;
	mov.u32 	%r343, 1;
	mov.f64 	%fd1812, %fd1811;

BB0_131:
	cvt.s64.s32	%rd1, %r344;
	mul.wide.s32 	%rd43, %r344, 8;
	add.s64 	%rd44, %rd9, %rd43;
	ld.global.f64 	%fd1810, [%rd44];
	abs.f64 	%fd1053, %fd1810;
	setp.gtu.f64	%p107, %fd1053, 0d7FF0000000000000;
	@%p107 bra 	BB0_133;

	shl.b64 	%rd45, %rd1, 3;
	add.s64 	%rd46, %rd10, %rd45;
	ld.global.f64 	%fd1809, [%rd46];
	abs.f64 	%fd1054, %fd1809;
	setp.le.f64	%p108, %fd1054, 0d7FF0000000000000;
	@%p108 bra 	BB0_134;

BB0_133:
	add.s32 	%r345, %r345, -1;
	mov.f64 	%fd1809, 0d0000000000000000;
	mov.f64 	%fd1810, %fd1809;

BB0_134:
	add.f64 	%fd1811, %fd1811, %fd1810;
	add.f64 	%fd1812, %fd1812, %fd1809;
	add.s32 	%r345, %r345, 1;
	cvt.u32.u64	%r239, %rd1;
	add.s32 	%r240, %r239, 1;
	setp.lt.s32	%p109, %r240, 6;
	setp.lt.s32	%p110, %r343, 2;
	and.pred  	%p111, %p110, %p109;
	add.s32 	%r344, %r344, 1;
	add.s32 	%r343, %r343, 1;
	@%p111 bra 	BB0_131;

BB0_135:
	setp.lt.s32	%p112, %r345, 1;
	mov.f64 	%fd1817, 0dFFF8000000000000;
	@%p112 bra 	BB0_143;

	cvt.rn.f64.s32	%fd159, %r345;
	mov.f64 	%fd1816, 0d0000000000000000;
	@%p1 bra 	BB0_142;

	mov.u32 	%r311, %tid.x;
	div.rn.f64 	%fd160, %fd1811, %fd159;
	div.rn.f64 	%fd161, %fd1812, %fd159;
	add.s32 	%r349, %r1, %r311;
	mov.f64 	%fd1816, 0d0000000000000000;
	mov.u32 	%r348, 1;

BB0_138:
	cvt.s64.s32	%rd2, %r349;
	mul.wide.s32 	%rd47, %r349, 8;
	add.s64 	%rd48, %rd9, %rd47;
	ld.global.f64 	%fd163, [%rd48];
	abs.f64 	%fd1060, %fd163;
	setp.gtu.f64	%p114, %fd1060, 0d7FF0000000000000;
	mov.f64 	%fd1814, %fd161;
	mov.f64 	%fd1815, %fd160;
	@%p114 bra 	BB0_141;

	shl.b64 	%rd49, %rd2, 3;
	add.s64 	%rd50, %rd10, %rd49;
	ld.global.f64 	%fd164, [%rd50];
	abs.f64 	%fd1061, %fd164;
	setp.gtu.f64	%p115, %fd1061, 0d7FF0000000000000;
	mov.f64 	%fd1814, %fd161;
	mov.f64 	%fd1815, %fd160;
	@%p115 bra 	BB0_141;

	mov.f64 	%fd1814, %fd164;
	mov.f64 	%fd1815, %fd163;

BB0_141:
	sub.f64 	%fd1062, %fd1814, %fd161;
	sub.f64 	%fd1063, %fd1815, %fd160;
	fma.rn.f64 	%fd1816, %fd1062, %fd1063, %fd1816;
	cvt.u32.u64	%r242, %rd2;
	add.s32 	%r243, %r242, 1;
	setp.lt.s32	%p116, %r243, 6;
	setp.lt.s32	%p117, %r348, 2;
	and.pred  	%p118, %p117, %p116;
	add.s32 	%r349, %r349, 1;
	add.s32 	%r348, %r348, 1;
	@%p118 bra 	BB0_138;

BB0_142:
	div.rn.f64 	%fd1817, %fd1816, %fd159;

BB0_143:
	mov.f64 	%fd173, 0d8000000000000000;
	setp.gt.s32	%p119, %r3, 4;
	@%p119 bra 	BB0_146;

	ld.param.u64 	%rd68, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3];
	mul.wide.s32 	%rd51, %r3, 8;
	add.s64 	%rd52, %rd68, %rd51;
	ld.global.f64 	%fd171, [%rd52];
	abs.f64 	%fd1066, %fd171;
	setp.gtu.f64	%p120, %fd1066, 0d7FF0000000000000;
	@%p120 bra 	BB0_146;

	mul.f64 	%fd173, %fd171, 0dBFE6A09E667F3BCC;

BB0_146:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r244}, %fd173; 
	}
	// inline asm
	setp.lt.s32	%p121, %r244, 1072168960;
	@%p121 bra 	BB0_153;
	bra.uni 	BB0_147;

BB0_153:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd173;
	}
	and.b32  	%r109, %r108, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r110, %temp}, %fd173;
	}
	setp.lt.u32	%p127, %r109, 1072693248;
	@%p127 bra 	BB0_159;
	bra.uni 	BB0_154;

BB0_159:
	mul.f64 	%fd1323, %fd173, %fd173;
	mov.f64 	%fd1324, 0d3E4D5F4BB7A316F6;
	mov.f64 	%fd1325, 0dBE0A83AA3B08FBC2;
	fma.rn.f64 	%fd1326, %fd1325, %fd1323, %fd1324;
	mov.f64 	%fd1327, 0dBE85BDCE301B3CDF;
	fma.rn.f64 	%fd1328, %fd1326, %fd1323, %fd1327;
	mov.f64 	%fd1329, 0d3EBB978FADB81BC9;
	fma.rn.f64 	%fd1330, %fd1328, %fd1323, %fd1329;
	mov.f64 	%fd1331, 0dBEEF4C99D6AE5FB8;
	fma.rn.f64 	%fd1332, %fd1330, %fd1323, %fd1331;
	mov.f64 	%fd1333, 0d3F1F9A2AF549012E;
	fma.rn.f64 	%fd1334, %fd1332, %fd1323, %fd1333;
	mov.f64 	%fd1335, 0dBF4C02DAFC636A47;
	fma.rn.f64 	%fd1336, %fd1334, %fd1323, %fd1335;
	mov.f64 	%fd1337, 0d3F7565BCCF619AC0;
	fma.rn.f64 	%fd1338, %fd1336, %fd1323, %fd1337;
	mov.f64 	%fd1339, 0dBF9B82CE311E321A;
	fma.rn.f64 	%fd1340, %fd1338, %fd1323, %fd1339;
	mov.f64 	%fd1341, 0d3FBCE2F21A04075C;
	fma.rn.f64 	%fd1342, %fd1340, %fd1323, %fd1341;
	mov.f64 	%fd1343, 0dBFD812746B0379B4;
	fma.rn.f64 	%fd1344, %fd1342, %fd1323, %fd1343;
	mov.f64 	%fd1345, 0d3FF20DD750429B6D;
	fma.rn.f64 	%fd1346, %fd1344, %fd1323, %fd1345;
	mul.f64 	%fd1820, %fd173, %fd1346;
	bra.uni 	BB0_160;

BB0_147:
	setp.gt.f64	%p122, %fd173, 0d403B4CCCCCCCCCCD;
	mov.f64 	%fd1821, 0d0000000000000000;
	@%p122 bra 	BB0_161;

	mul.rn.f64 	%fd1073, %fd173, %fd173;
	neg.f64 	%fd1072, %fd1073;
	// inline asm
	fma.rn.f64 	%fd1069, %fd173, %fd173, %fd1072;
	// inline asm
	mov.f64 	%fd1074, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1819, %fd1072, %fd1074;
	abs.f64 	%fd177, %fd1819;
	setp.ge.f64	%p123, %fd177, 0d4330000000000000;
	@%p123 bra 	BB0_150;

	add.f64 	%fd1075, %fd177, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd1076, %fd1075;
	setp.lt.f64	%p124, %fd177, 0d3FE0000000000000;
	selp.f64	%fd1077, 0d0000000000000000, %fd1076, %p124;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r245, %temp}, %fd1077;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r246}, %fd1077;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd1819;
	}
	and.b32  	%r248, %r247, -2147483648;
	or.b32  	%r249, %r246, %r248;
	mov.b64 	%fd1819, {%r245, %r249};

BB0_150:
	mov.f64 	%fd1080, 0dBFE62E42FEFA39EF;
	// inline asm
	fma.rn.f64 	%fd1078, %fd1819, %fd1080, %fd1072;
	// inline asm
	mov.f64 	%fd1084, 0dBC7ABC9E3B39803F;
	// inline asm
	fma.rn.f64 	%fd1082, %fd1819, %fd1084, %fd1078;
	// inline asm
	cvt.rzi.s32.f64	%r252, %fd1819;
	setp.lt.s32	%p125, %r252, -1020;
	add.s32 	%r253, %r252, 55;
	selp.f64	%fd1139, 0d3C90000000000000, 0d4000000000000000, %p125;
	selp.b32	%r254, %r253, %r252, %p125;
	mov.f64 	%fd1087, 0d3E21F07FCCF58BAD;
	mov.f64 	%fd1089, 0d3E5AFD81DA6C3BAF;
	// inline asm
	fma.rn.f64 	%fd1086, %fd1087, %fd1082, %fd1089;
	// inline asm
	mov.f64 	%fd1093, 0d3E927E55F60F80E6;
	// inline asm
	fma.rn.f64 	%fd1090, %fd1086, %fd1082, %fd1093;
	// inline asm
	mov.f64 	%fd1097, 0d3EC71DDA8F02D666;
	// inline asm
	fma.rn.f64 	%fd1094, %fd1090, %fd1082, %fd1097;
	// inline asm
	mov.f64 	%fd1101, 0d3EFA01A013B894E0;
	// inline asm
	fma.rn.f64 	%fd1098, %fd1094, %fd1082, %fd1101;
	// inline asm
	mov.f64 	%fd1105, 0d3F2A01A01D3AF788;
	// inline asm
	fma.rn.f64 	%fd1102, %fd1098, %fd1082, %fd1105;
	// inline asm
	mov.f64 	%fd1109, 0d3F56C16C16C3A1EC;
	// inline asm
	fma.rn.f64 	%fd1106, %fd1102, %fd1082, %fd1109;
	// inline asm
	mov.f64 	%fd1113, 0d3F81111111109161;
	// inline asm
	fma.rn.f64 	%fd1110, %fd1106, %fd1082, %fd1113;
	// inline asm
	mov.f64 	%fd1117, 0d3FA55555555554C1;
	// inline asm
	fma.rn.f64 	%fd1114, %fd1110, %fd1082, %fd1117;
	// inline asm
	mov.f64 	%fd1121, 0d3FC555555555556F;
	// inline asm
	fma.rn.f64 	%fd1118, %fd1114, %fd1082, %fd1121;
	// inline asm
	mov.f64 	%fd1125, 0d3FE0000000000000;
	// inline asm
	fma.rn.f64 	%fd1122, %fd1118, %fd1082, %fd1125;
	// inline asm
	mul.rn.f64 	%fd1127, %fd1122, %fd1082;
	// inline asm
	fma.rn.f64 	%fd1126, %fd1127, %fd1082, %fd1082;
	// inline asm
	add.s32 	%r255, %r254, 1022;
	shl.b32 	%r251, %r255, 20;
	mov.u32 	%r250, 0;
	// inline asm
	mov.b64 	%fd1130, {%r250, %r251};
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1131, %fd1126, %fd1130, %fd1130;
	// inline asm
	mul.rn.f64 	%fd1138, %fd1131, %fd1139;
	neg.f64 	%fd1137, %fd1138;
	// inline asm
	fma.rn.f64 	%fd1135, %fd1069, %fd1137, %fd1138;
	// inline asm
	setp.lt.s32	%p126, %r244, 1075052544;
	@%p126 bra 	BB0_152;
	bra.uni 	BB0_151;

BB0_152:
	mov.f64 	%fd1187, 0d3FE20DD7452FBC22;
	mov.f64 	%fd1189, 0d401FD453E105E9A2;
	// inline asm
	fma.rn.f64 	%fd1186, %fd1187, %fd173, %fd1189;
	// inline asm
	mov.f64 	%fd1193, 0d404B26245B951FB4;
	// inline asm
	fma.rn.f64 	%fd1190, %fd1186, %fd173, %fd1193;
	// inline asm
	mov.f64 	%fd1197, 0d406C7835DC0F1F49;
	// inline asm
	fma.rn.f64 	%fd1194, %fd1190, %fd173, %fd1197;
	// inline asm
	mov.f64 	%fd1201, 0d4083AFA471E5C766;
	// inline asm
	fma.rn.f64 	%fd1198, %fd1194, %fd173, %fd1201;
	// inline asm
	mov.f64 	%fd1205, 0d4091FB514824F49F;
	// inline asm
	fma.rn.f64 	%fd1202, %fd1198, %fd173, %fd1205;
	// inline asm
	mov.f64 	%fd1209, 0d409450DDEE8272BB;
	// inline asm
	fma.rn.f64 	%fd1206, %fd1202, %fd173, %fd1209;
	// inline asm
	mov.f64 	%fd1213, 0d4086B952E4ECBC50;
	// inline asm
	fma.rn.f64 	%fd1210, %fd1206, %fd173, %fd1213;
	// inline asm
	add.f64 	%fd1215, %fd173, 0d402C35442E99E667;
	mov.f64 	%fd1217, 0d40582F68071A079D;
	// inline asm
	fma.rn.f64 	%fd1214, %fd1215, %fd173, %fd1217;
	// inline asm
	mov.f64 	%fd1221, 0d4079ABD39A029DAA;
	// inline asm
	fma.rn.f64 	%fd1218, %fd1214, %fd173, %fd1221;
	// inline asm
	mov.f64 	%fd1225, 0d409230CA327093FD;
	// inline asm
	fma.rn.f64 	%fd1222, %fd1218, %fd173, %fd1225;
	// inline asm
	mov.f64 	%fd1229, 0d40A174FAB33B54A7;
	// inline asm
	fma.rn.f64 	%fd1226, %fd1222, %fd173, %fd1229;
	// inline asm
	mov.f64 	%fd1233, 0d40A601508230F980;
	// inline asm
	fma.rn.f64 	%fd1230, %fd1226, %fd173, %fd1233;
	// inline asm
	mov.f64 	%fd1237, 0d40A091785EC9331E;
	// inline asm
	fma.rn.f64 	%fd1234, %fd1230, %fd173, %fd1237;
	// inline asm
	mov.f64 	%fd1241, 0d4086B952E52F3622;
	// inline asm
	fma.rn.f64 	%fd1238, %fd1234, %fd173, %fd1241;
	// inline asm
	div.rn.f64 	%fd1242, %fd1210, %fd1238;
	mul.rn.f64 	%fd1821, %fd1242, %fd1135;
	bra.uni 	BB0_161;

BB0_154:
	setp.lt.u32	%p128, %r109, 2146435072;
	@%p128 bra 	BB0_158;
	bra.uni 	BB0_155;

BB0_158:
	mov.b64 	%fd1244, {%r110, %r109};
	mov.f64 	%fd1245, 0dBCF1384CE38C616A;
	mov.f64 	%fd1246, 0d3C8B9C2B870030E8;
	fma.rn.f64 	%fd1247, %fd1246, %fd1244, %fd1245;
	mov.f64 	%fd1248, 0d3D4458AE9746C2FD;
	fma.rn.f64 	%fd1249, %fd1247, %fd1244, %fd1248;
	mov.f64 	%fd1250, 0dBD8E4A44D4F1AB56;
	fma.rn.f64 	%fd1251, %fd1249, %fd1244, %fd1250;
	mov.f64 	%fd1252, 0d3DCFDF15265C58EE;
	fma.rn.f64 	%fd1253, %fd1251, %fd1244, %fd1252;
	mov.f64 	%fd1254, 0dBE0933832F358D51;
	fma.rn.f64 	%fd1255, %fd1253, %fd1244, %fd1254;
	mov.f64 	%fd1256, 0d3E3F136D3F719446;
	fma.rn.f64 	%fd1257, %fd1255, %fd1244, %fd1256;
	mov.f64 	%fd1258, 0dBE6E94C2FE151B3B;
	fma.rn.f64 	%fd1259, %fd1257, %fd1244, %fd1258;
	mov.f64 	%fd1260, 0d3E985A70310EE0A8;
	fma.rn.f64 	%fd1261, %fd1259, %fd1244, %fd1260;
	mov.f64 	%fd1262, 0dBEBF944DA1520B74;
	fma.rn.f64 	%fd1263, %fd1261, %fd1244, %fd1262;
	mov.f64 	%fd1264, 0d3EE09F503825C543;
	fma.rn.f64 	%fd1265, %fd1263, %fd1244, %fd1264;
	mov.f64 	%fd1266, 0dBEFBEEFE9F949E59;
	fma.rn.f64 	%fd1267, %fd1265, %fd1244, %fd1266;
	mov.f64 	%fd1268, 0d3F11D785C6E28857;
	fma.rn.f64 	%fd1269, %fd1267, %fd1244, %fd1268;
	mov.f64 	%fd1270, 0dBF1D866B223048C7;
	fma.rn.f64 	%fd1271, %fd1269, %fd1244, %fd1270;
	mov.f64 	%fd1272, 0d3EF258F0847E8908;
	fma.rn.f64 	%fd1273, %fd1271, %fd1244, %fd1272;
	mov.f64 	%fd1274, 0d3F429CFC58DBB776;
	fma.rn.f64 	%fd1275, %fd1273, %fd1244, %fd1274;
	mov.f64 	%fd1276, 0dBF5BE16D3F71F3C5;
	fma.rn.f64 	%fd1277, %fd1275, %fd1244, %fd1276;
	mov.f64 	%fd1278, 0d3F2E8BDA60326B1A;
	fma.rn.f64 	%fd1279, %fd1277, %fd1244, %fd1278;
	mov.f64 	%fd1280, 0d3F938FB20B0988A6;
	fma.rn.f64 	%fd1281, %fd1279, %fd1244, %fd1280;
	mov.f64 	%fd1282, 0dBFBA4E3A80F64E33;
	fma.rn.f64 	%fd1283, %fd1281, %fd1244, %fd1282;
	mov.f64 	%fd1284, 0dBFE45F3E88093928;
	fma.rn.f64 	%fd1285, %fd1283, %fd1244, %fd1284;
	mov.f64 	%fd1286, 0dBFF20DD599CAEEA0;
	fma.rn.f64 	%fd1287, %fd1285, %fd1244, %fd1286;
	mov.f64 	%fd1288, 0dBE883BE1E31CE133;
	fma.rn.f64 	%fd1289, %fd1287, %fd1244, %fd1288;
	mov.f64 	%fd1290, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1291, %fd1289, %fd1290;
	mov.f64 	%fd1292, 0d4338000000000000;
	add.rn.f64 	%fd1293, %fd1291, %fd1292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r260, %temp}, %fd1293;
	}
	mov.f64 	%fd1294, 0dC338000000000000;
	add.rn.f64 	%fd1295, %fd1293, %fd1294;
	mov.f64 	%fd1296, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1297, %fd1295, %fd1296, %fd1289;
	mov.f64 	%fd1298, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1299, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1300, %fd1299, %fd1297, %fd1298;
	mov.f64 	%fd1301, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1302, %fd1300, %fd1297, %fd1301;
	mov.f64 	%fd1303, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1304, %fd1302, %fd1297, %fd1303;
	mov.f64 	%fd1305, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1306, %fd1304, %fd1297, %fd1305;
	mov.f64 	%fd1307, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1308, %fd1306, %fd1297, %fd1307;
	mov.f64 	%fd1309, 0d3F81111111122322;
	fma.rn.f64 	%fd1310, %fd1308, %fd1297, %fd1309;
	mov.f64 	%fd1311, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1312, %fd1310, %fd1297, %fd1311;
	mov.f64 	%fd1313, 0d3FC5555555555511;
	fma.rn.f64 	%fd1314, %fd1312, %fd1297, %fd1313;
	mov.f64 	%fd1315, 0d3FE000000000000B;
	fma.rn.f64 	%fd1316, %fd1314, %fd1297, %fd1315;
	mov.f64 	%fd1317, 0d3FF0000000000000;
	fma.rn.f64 	%fd1318, %fd1316, %fd1297, %fd1317;
	fma.rn.f64 	%fd1319, %fd1318, %fd1297, %fd1317;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r261}, %fd1319;
	}
	shl.b32 	%r262, %r260, 20;
	add.s32 	%r263, %r261, %r262;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r264, %temp}, %fd1319;
	}
	mov.b64 	%fd1320, {%r264, %r263};
	sub.f64 	%fd1321, %fd1317, %fd1320;
	setp.gt.u32	%p132, %r109, 1075294207;
	selp.f64	%fd1322, 0d3FF0000000000000, %fd1321, %p132;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r265, %temp}, %fd1322;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r266}, %fd1322;
	}
	and.b32  	%r267, %r108, -2147483648;
	or.b32  	%r268, %r266, %r267;
	mov.b64 	%fd1820, {%r265, %r268};
	bra.uni 	BB0_160;

BB0_151:
	rcp.rn.f64 	%fd1184, %fd173;
	mul.rn.f64 	%fd1182, %fd1184, %fd1184;
	mov.f64 	%fd1141, 0dC1186DF84479631D;
	mov.f64 	%fd1143, 0d41019A6E9A7FFBB8;
	// inline asm
	fma.rn.f64 	%fd1140, %fd1141, %fd1182, %fd1143;
	// inline asm
	mov.f64 	%fd1147, 0dC0DB040BE3D5CA18;
	// inline asm
	fma.rn.f64 	%fd1144, %fd1140, %fd1182, %fd1147;
	// inline asm
	mov.f64 	%fd1151, 0d40B012760EE009A0;
	// inline asm
	fma.rn.f64 	%fd1148, %fd1144, %fd1182, %fd1151;
	// inline asm
	mov.f64 	%fd1155, 0dC082587AE4008D0E;
	// inline asm
	fma.rn.f64 	%fd1152, %fd1148, %fd1182, %fd1155;
	// inline asm
	mov.f64 	%fd1159, 0d4056DF5D938ACAFE;
	// inline asm
	fma.rn.f64 	%fd1156, %fd1152, %fd1182, %fd1159;
	// inline asm
	mov.f64 	%fd1163, 0dC030A8D46D765681;
	// inline asm
	fma.rn.f64 	%fd1160, %fd1156, %fd1182, %fd1163;
	// inline asm
	mov.f64 	%fd1167, 0d400D9EAE0C665C75;
	// inline asm
	fma.rn.f64 	%fd1164, %fd1160, %fd1182, %fd1167;
	// inline asm
	mov.f64 	%fd1171, 0dBFF0ECF9C8880942;
	// inline asm
	fma.rn.f64 	%fd1168, %fd1164, %fd1182, %fd1171;
	// inline asm
	mov.f64 	%fd1175, 0d3FDB14C2F82A33F7;
	// inline asm
	fma.rn.f64 	%fd1172, %fd1168, %fd1182, %fd1175;
	// inline asm
	mov.f64 	%fd1179, 0dBFD20DD75042844F;
	// inline asm
	fma.rn.f64 	%fd1176, %fd1172, %fd1182, %fd1179;
	// inline asm
	mov.f64 	%fd1183, 0d3FE20DD750429B6B;
	// inline asm
	fma.rn.f64 	%fd1180, %fd1176, %fd1182, %fd1183;
	// inline asm
	mul.rn.f64 	%fd1185, %fd1180, %fd1184;
	mul.rn.f64 	%fd1821, %fd1185, %fd1135;
	bra.uni 	BB0_161;

BB0_155:
	setp.eq.s32	%p129, %r109, 2146435072;
	setp.eq.s32	%p130, %r110, 0;
	and.pred  	%p131, %p129, %p130;
	@%p131 bra 	BB0_157;
	bra.uni 	BB0_156;

BB0_157:
	mov.f64 	%fd1243, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r256, %temp}, %fd1243;
	}
	and.b32  	%r257, %r108, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r258}, %fd1243;
	}
	or.b32  	%r259, %r258, %r257;
	mov.b64 	%fd1820, {%r256, %r259};
	bra.uni 	BB0_160;

BB0_156:
	add.f64 	%fd1820, %fd173, %fd173;

BB0_160:
	mov.f64 	%fd1347, 0d3FF0000000000000;
	sub.f64 	%fd1821, %fd1347, %fd1820;

BB0_161:
	ld.param.u64 	%rd65, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2];
	fma.rn.f64 	%fd190, %fd1821, 0d3FE0000000000000, 0d0000000000000000;
	mul.wide.s32 	%rd53, %r3, 8;
	add.s64 	%rd3, %rd65, %rd53;
	mov.f64 	%fd1822, 0d0000000000000000;
	mov.f64 	%fd1823, %fd1822;
	@%p119 bra 	BB0_163;

	ld.global.f64 	%fd1350, [%rd3];
	abs.f64 	%fd1351, %fd1350;
	setp.gtu.f64	%p134, %fd1351, 0d7FF0000000000000;
	add.f64 	%fd1352, %fd1350, 0d0000000000000000;
	selp.f64	%fd1822, 0d0000000000000000, %fd1352, %p134;
	selp.f64	%fd1823, 0d0000000000000000, 0d3FF0000000000000, %p134;

BB0_163:
	ld.param.u64 	%rd66, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1];
	add.s64 	%rd4, %rd66, %rd53;
	@%p119 bra 	BB0_165;

	ld.global.f64 	%fd1353, [%rd4];
	abs.f64 	%fd1354, %fd1353;
	setp.gtu.f64	%p136, %fd1354, 0d7FF0000000000000;
	add.f64 	%fd1355, %fd1822, %fd1353;
	selp.f64	%fd1822, %fd1822, %fd1355, %p136;
	add.f64 	%fd1356, %fd1823, 0d3FF0000000000000;
	selp.f64	%fd1823, %fd1823, %fd1356, %p136;

BB0_165:
	setp.eq.f64	%p137, %fd1823, 0d3FF0000000000000;
	mov.f64 	%fd1830, 0d3FF0000000000000;
	@%p137 bra 	BB0_191;

	abs.f64 	%fd199, %fd1823;
	setp.gtu.f64	%p138, %fd199, 0d7FF0000000000000;
	@%p138 bra 	BB0_190;
	bra.uni 	BB0_167;

BB0_190:
	add.f64 	%fd1830, %fd1823, 0dBFF0000000000000;
	bra.uni 	BB0_191;

BB0_167:
	setp.eq.f64	%p139, %fd1823, 0d7FF0000000000000;
	@%p139 bra 	BB0_189;
	bra.uni 	BB0_168;

BB0_189:
	mov.f64 	%fd1548, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r289}, %fd1548;
	}
	setp.gt.s32	%p156, %r289, -1;
	selp.f64	%fd1830, 0d7FF0000000000000, 0d0000000000000000, %p156;
	bra.uni 	BB0_191;

BB0_168:
	mov.f64 	%fd1358, 0dBFF0000000000000;
	mov.f64 	%fd1359, 0d3FE0000000000000;
	mul.rn.f64 	%fd1360, %fd1359, %fd1358;
	cvt.rzi.f64.f64	%fd1361, %fd1360;
	mov.f64 	%fd1362, 0d4000000000000000;
	mul.rn.f64 	%fd1363, %fd1362, %fd1361;
	sub.f64 	%fd1364, %fd1358, %fd1363;
	abs.f64 	%fd200, %fd1364;
	setp.eq.f64	%p140, %fd1823, 0d0000000000000000;
	@%p140 bra 	BB0_188;
	bra.uni 	BB0_169;

BB0_188:
	setp.eq.f64	%p155, %fd200, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1545, %fd1823;
	mov.f64 	%fd1546, 0d0000000000000000;
	rcp.rn.f64 	%fd1547, %fd1546;
	selp.f64	%fd1830, %fd1545, %fd1547, %p155;
	bra.uni 	BB0_191;

BB0_169:
	setp.eq.f64	%p141, %fd1823, 0dFFF0000000000000;
	@%p141 bra 	BB0_186;
	bra.uni 	BB0_170;

BB0_186:
	div.rn.f64 	%fd1830, %fd1358, %fd1823;
	setp.neu.f64	%p154, %fd200, 0d3FF0000000000000;
	@%p154 bra 	BB0_191;

	mov.b64 	 %rd57, %fd1830;
	xor.b64  	%rd58, %rd57, -9223372036854775808;
	mov.b64 	 %fd1830, %rd58;
	bra.uni 	BB0_191;

BB0_170:
	setp.geu.f64	%p142, %fd1823, 0d0000000000000000;
	@%p142 bra 	BB0_172;

	cvt.rzi.f64.f64	%fd1367, %fd1358;
	setp.neu.f64	%p143, %fd1367, 0dBFF0000000000000;
	mov.f64 	%fd1830, 0dFFF8000000000000;
	@%p143 bra 	BB0_191;

BB0_172:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r351}, %fd199; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r350, hi}, %fd199; 
	}
	// inline asm
	bfe.u32 	%r352, %r351, 20, 11;
	setp.ne.s32	%p144, %r352, 0;
	@%p144 bra 	BB0_174;

	mov.f64 	%fd1372, 0d4350000000000000;
	mul.rn.f64 	%fd1371, %fd199, %fd1372;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r351}, %fd1371; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r350, hi}, %fd1371; 
	}
	// inline asm
	bfe.u32 	%r273, %r351, 20, 11;
	add.s32 	%r352, %r273, -54;

BB0_174:
	add.s32 	%r353, %r352, -1023;
	and.b32  	%r276, %r351, -2146435073;
	or.b32  	%r275, %r276, 1072693248;
	// inline asm
	mov.b64 	%fd1826, {%r350, %r275};
	// inline asm
	setp.lt.u32	%p145, %r275, 1073127583;
	@%p145 bra 	BB0_176;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r277, hi}, %fd1826; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r278}, %fd1826; 
	}
	// inline asm
	add.s32 	%r280, %r278, -1048576;
	// inline asm
	mov.b64 	%fd1826, {%r277, %r280};
	// inline asm
	add.s32 	%r353, %r352, -1022;

BB0_176:
	add.f64 	%fd1461, %fd1826, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1462, %fd1461;
	add.f64 	%fd1403, %fd1826, 0dBFF0000000000000;
	mul.rn.f64 	%fd1463, %fd1403, %fd1462;
	add.f64 	%fd1451, %fd1463, %fd1463;
	mul.rn.f64 	%fd1399, %fd1451, %fd1451;
	mov.f64 	%fd1378, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1380, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1377, %fd1378, %fd1399, %fd1380;
	// inline asm
	mov.f64 	%fd1384, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1381, %fd1377, %fd1399, %fd1384;
	// inline asm
	mov.f64 	%fd1388, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1385, %fd1381, %fd1399, %fd1388;
	// inline asm
	mov.f64 	%fd1392, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1389, %fd1385, %fd1399, %fd1392;
	// inline asm
	mov.f64 	%fd1396, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1393, %fd1389, %fd1399, %fd1396;
	// inline asm
	mov.f64 	%fd1400, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1397, %fd1393, %fd1399, %fd1400;
	// inline asm
	mul.rn.f64 	%fd1464, %fd1397, %fd1399;
	sub.f64 	%fd1465, %fd1403, %fd1451;
	mul.rn.f64 	%fd1404, %fd1362, %fd1465;
	neg.f64 	%fd1402, %fd1451;
	// inline asm
	fma.rn.f64 	%fd1401, %fd1402, %fd1403, %fd1404;
	// inline asm
	mul.rn.f64 	%fd1447, %fd1462, %fd1401;
	add.f64 	%fd1467, %fd1464, 0d3FB5555555555555;
	mov.f64 	%fd1468, 0d3FB5555555555555;
	sub.f64 	%fd1469, %fd1468, %fd1467;
	add.f64 	%fd1470, %fd1464, %fd1469;
	add.f64 	%fd1471, %fd1470, 0d0000000000000000;
	add.f64 	%fd1472, %fd1471, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1414, %fd1467, %fd1472;
	sub.f64 	%fd1473, %fd1467, %fd1414;
	add.f64 	%fd1418, %fd1472, %fd1473;
	mul.rn.f64 	%fd1474, %fd1414, %fd1451;
	neg.f64 	%fd1408, %fd1474;
	// inline asm
	fma.rn.f64 	%fd1405, %fd1414, %fd1451, %fd1408;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1409, %fd1418, %fd1447, %fd1405;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1413, %fd1414, %fd1447, %fd1409;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1417, %fd1418, %fd1451, %fd1413;
	// inline asm
	add.f64 	%fd1430, %fd1474, %fd1417;
	sub.f64 	%fd1475, %fd1474, %fd1430;
	add.f64 	%fd1434, %fd1417, %fd1475;
	mul.rn.f64 	%fd1476, %fd1430, %fd1451;
	neg.f64 	%fd1424, %fd1476;
	// inline asm
	fma.rn.f64 	%fd1421, %fd1430, %fd1451, %fd1424;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1425, %fd1434, %fd1447, %fd1421;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1429, %fd1430, %fd1447, %fd1425;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1433, %fd1434, %fd1451, %fd1429;
	// inline asm
	add.f64 	%fd1446, %fd1476, %fd1433;
	sub.f64 	%fd1477, %fd1476, %fd1446;
	add.f64 	%fd1450, %fd1433, %fd1477;
	mul.rn.f64 	%fd1478, %fd1446, %fd1451;
	neg.f64 	%fd1440, %fd1478;
	// inline asm
	fma.rn.f64 	%fd1437, %fd1446, %fd1451, %fd1440;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1441, %fd1450, %fd1447, %fd1437;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1445, %fd1446, %fd1447, %fd1441;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1449, %fd1450, %fd1451, %fd1445;
	// inline asm
	add.f64 	%fd1479, %fd1478, %fd1449;
	sub.f64 	%fd1480, %fd1478, %fd1479;
	add.f64 	%fd1481, %fd1449, %fd1480;
	add.f64 	%fd1482, %fd1451, %fd1479;
	sub.f64 	%fd1483, %fd1451, %fd1482;
	add.f64 	%fd1484, %fd1479, %fd1483;
	add.f64 	%fd1485, %fd1481, %fd1484;
	add.f64 	%fd1486, %fd1447, %fd1485;
	add.f64 	%fd1487, %fd1482, %fd1486;
	sub.f64 	%fd1488, %fd1482, %fd1487;
	add.f64 	%fd1489, %fd1486, %fd1488;
	cvt.rn.f64.s32	%fd1490, %r353;
	mov.f64 	%fd1491, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1492, %fd1490, %fd1491;
	mov.f64 	%fd1493, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1494, %fd1490, %fd1493;
	add.f64 	%fd1495, %fd1492, %fd1487;
	sub.f64 	%fd1496, %fd1492, %fd1495;
	add.f64 	%fd1497, %fd1487, %fd1496;
	add.f64 	%fd1498, %fd1489, %fd1497;
	add.f64 	%fd1499, %fd1494, %fd1498;
	add.f64 	%fd1454, %fd1495, %fd1499;
	sub.f64 	%fd1500, %fd1495, %fd1454;
	add.f64 	%fd1458, %fd1499, %fd1500;
	mul.rn.f64 	%fd1501, %fd1454, %fd1358;
	neg.f64 	%fd1456, %fd1501;
	// inline asm
	fma.rn.f64 	%fd1453, %fd1454, %fd1358, %fd1456;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1457, %fd1458, %fd1358, %fd1453;
	// inline asm
	add.f64 	%fd204, %fd1501, %fd1457;
	sub.f64 	%fd1502, %fd1501, %fd204;
	add.f64 	%fd205, %fd1457, %fd1502;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd204;
	}
	mov.b32 	 %f9, %r123;
	abs.f32 	%f10, %f9;
	setp.lt.f32	%p146, %f10, 0f40874911;
	@%p146 bra 	BB0_178;
	bra.uni 	BB0_177;

BB0_178:
	mov.f64 	%fd1506, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1507, %fd204, %fd1506;
	mov.f64 	%fd1508, 0d4338000000000000;
	add.rn.f64 	%fd1509, %fd1507, %fd1508;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd1509;
	}
	mov.f64 	%fd1510, 0dC338000000000000;
	add.rn.f64 	%fd1511, %fd1509, %fd1510;
	mov.f64 	%fd1512, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1513, %fd1511, %fd1512, %fd204;
	mov.f64 	%fd1514, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1515, %fd1511, %fd1514, %fd1513;
	mov.f64 	%fd1516, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1517, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1518, %fd1517, %fd1515, %fd1516;
	mov.f64 	%fd1519, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1520, %fd1518, %fd1515, %fd1519;
	mov.f64 	%fd1521, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1522, %fd1520, %fd1515, %fd1521;
	mov.f64 	%fd1523, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1524, %fd1522, %fd1515, %fd1523;
	mov.f64 	%fd1525, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1526, %fd1524, %fd1515, %fd1525;
	mov.f64 	%fd1527, 0d3F81111111122322;
	fma.rn.f64 	%fd1528, %fd1526, %fd1515, %fd1527;
	mov.f64 	%fd1529, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1530, %fd1528, %fd1515, %fd1529;
	mov.f64 	%fd1531, 0d3FC5555555555511;
	fma.rn.f64 	%fd1532, %fd1530, %fd1515, %fd1531;
	mov.f64 	%fd1533, 0d3FE000000000000B;
	fma.rn.f64 	%fd1534, %fd1532, %fd1515, %fd1533;
	mov.f64 	%fd1535, 0d3FF0000000000000;
	fma.rn.f64 	%fd1536, %fd1534, %fd1515, %fd1535;
	fma.rn.f64 	%fd1827, %fd1536, %fd1515, %fd1535;
	abs.s32 	%r281, %r124;
	setp.lt.s32	%p149, %r281, 1023;
	@%p149 bra 	BB0_180;
	bra.uni 	BB0_179;

BB0_180:
	shl.b32 	%r287, %r124, 20;
	add.s32 	%r354, %r287, 1072693248;
	bra.uni 	BB0_181;

BB0_177:
	setp.lt.s32	%p147, %r123, 0;
	selp.f64	%fd1503, 0d0000000000000000, 0d7FF0000000000000, %p147;
	abs.f64 	%fd1504, %fd204;
	setp.gtu.f64	%p148, %fd1504, 0d7FF0000000000000;
	add.f64 	%fd1505, %fd204, %fd204;
	selp.f64	%fd1830, %fd1505, %fd1503, %p148;
	bra.uni 	BB0_182;

BB0_179:
	add.s32 	%r282, %r124, 2046;
	shl.b32 	%r283, %r282, 19;
	and.b32  	%r284, %r283, -1048576;
	shl.b32 	%r285, %r282, 20;
	sub.s32 	%r354, %r285, %r284;
	mov.u32 	%r286, 0;
	mov.b64 	%fd1537, {%r286, %r284};
	mul.f64 	%fd1827, %fd1827, %fd1537;

BB0_181:
	mov.u32 	%r288, 0;
	mov.b64 	%fd1538, {%r288, %r354};
	mul.f64 	%fd1830, %fd1827, %fd1538;

BB0_182:
	abs.f64 	%fd1539, %fd1830;
	setp.eq.f64	%p150, %fd1539, 0d7FF0000000000000;
	@%p150 bra 	BB0_184;

	// inline asm
	fma.rn.f64 	%fd1830, %fd1830, %fd205, %fd1830;
	// inline asm

BB0_184:
	setp.neu.f64	%p151, %fd200, 0d3FF0000000000000;
	or.pred  	%p153, %p142, %p151;
	@%p153 bra 	BB0_191;

	mov.b64 	 %rd55, %fd1830;
	xor.b64  	%rd56, %rd55, -9223372036854775808;
	mov.b64 	 %fd1830, %rd56;

BB0_191:
	mul.f64 	%fd221, %fd1822, %fd1830;
	mov.f64 	%fd1831, 0d0000000000000000;
	@%p119 bra 	BB0_194;

	ld.global.f64 	%fd222, [%rd3];
	abs.f64 	%fd1551, %fd222;
	setp.gtu.f64	%p158, %fd1551, 0d7FF0000000000000;
	@%p158 bra 	BB0_194;

	sub.f64 	%fd1552, %fd222, %fd221;
	fma.rn.f64 	%fd1831, %fd1552, %fd1552, 0d0000000000000000;

BB0_194:
	@%p119 bra 	BB0_197;

	ld.global.f64 	%fd225, [%rd4];
	abs.f64 	%fd1553, %fd225;
	setp.gtu.f64	%p160, %fd1553, 0d7FF0000000000000;
	@%p160 bra 	BB0_197;

	sub.f64 	%fd1554, %fd225, %fd221;
	fma.rn.f64 	%fd1831, %fd1554, %fd1554, %fd1831;

BB0_197:
	mov.f64 	%fd1838, 0dFFF8000000000000;
	setp.le.f64	%p161, %fd1823, 0d3FF0000000000000;
	@%p161 bra 	BB0_225;

	add.f64 	%fd228, %fd1823, 0dBFF0000000000000;
	setp.eq.f64	%p162, %fd228, 0d3FF0000000000000;
	mov.f64 	%fd1837, 0d3FF0000000000000;
	@%p162 bra 	BB0_224;

	abs.f64 	%fd229, %fd228;
	setp.gtu.f64	%p163, %fd229, 0d7FF0000000000000;
	@%p163 bra 	BB0_223;
	bra.uni 	BB0_200;

BB0_223:
	add.f64 	%fd1837, %fd228, 0dBFF0000000000000;
	bra.uni 	BB0_224;

BB0_200:
	setp.eq.f64	%p164, %fd228, 0d7FF0000000000000;
	@%p164 bra 	BB0_222;
	bra.uni 	BB0_201;

BB0_222:
	mov.f64 	%fd1747, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r310}, %fd1747;
	}
	setp.gt.s32	%p181, %r310, -1;
	selp.f64	%fd1837, 0d7FF0000000000000, 0d0000000000000000, %p181;
	bra.uni 	BB0_224;

BB0_201:
	mov.f64 	%fd1557, 0dBFF0000000000000;
	mov.f64 	%fd1558, 0d3FE0000000000000;
	mul.rn.f64 	%fd1559, %fd1558, %fd1557;
	cvt.rzi.f64.f64	%fd1560, %fd1559;
	mov.f64 	%fd1561, 0d4000000000000000;
	mul.rn.f64 	%fd1562, %fd1561, %fd1560;
	sub.f64 	%fd1563, %fd1557, %fd1562;
	abs.f64 	%fd230, %fd1563;
	setp.eq.f64	%p165, %fd228, 0d0000000000000000;
	@%p165 bra 	BB0_221;
	bra.uni 	BB0_202;

BB0_221:
	setp.eq.f64	%p180, %fd230, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1744, %fd228;
	mov.f64 	%fd1745, 0d0000000000000000;
	rcp.rn.f64 	%fd1746, %fd1745;
	selp.f64	%fd1837, %fd1744, %fd1746, %p180;
	bra.uni 	BB0_224;

BB0_202:
	setp.eq.f64	%p166, %fd228, 0dFFF0000000000000;
	@%p166 bra 	BB0_219;
	bra.uni 	BB0_203;

BB0_219:
	div.rn.f64 	%fd1837, %fd1557, %fd228;
	setp.neu.f64	%p179, %fd230, 0d3FF0000000000000;
	@%p179 bra 	BB0_224;

	mov.b64 	 %rd61, %fd1837;
	xor.b64  	%rd62, %rd61, -9223372036854775808;
	mov.b64 	 %fd1837, %rd62;
	bra.uni 	BB0_224;

BB0_203:
	setp.geu.f64	%p167, %fd228, 0d0000000000000000;
	@%p167 bra 	BB0_205;

	cvt.rzi.f64.f64	%fd1566, %fd1557;
	setp.neu.f64	%p168, %fd1566, 0dBFF0000000000000;
	mov.f64 	%fd1837, 0dFFF8000000000000;
	@%p168 bra 	BB0_224;

BB0_205:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r356}, %fd229; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r355, hi}, %fd229; 
	}
	// inline asm
	bfe.u32 	%r357, %r356, 20, 11;
	setp.ne.s32	%p169, %r357, 0;
	@%p169 bra 	BB0_207;

	mov.f64 	%fd1571, 0d4350000000000000;
	mul.rn.f64 	%fd1570, %fd229, %fd1571;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r356}, %fd1570; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r355, hi}, %fd1570; 
	}
	// inline asm
	bfe.u32 	%r294, %r356, 20, 11;
	add.s32 	%r357, %r294, -54;

BB0_207:
	add.s32 	%r358, %r357, -1023;
	and.b32  	%r297, %r356, -2146435073;
	or.b32  	%r296, %r297, 1072693248;
	// inline asm
	mov.b64 	%fd1833, {%r355, %r296};
	// inline asm
	setp.lt.u32	%p170, %r296, 1073127583;
	@%p170 bra 	BB0_209;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r298, hi}, %fd1833; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r299}, %fd1833; 
	}
	// inline asm
	add.s32 	%r301, %r299, -1048576;
	// inline asm
	mov.b64 	%fd1833, {%r298, %r301};
	// inline asm
	add.s32 	%r358, %r357, -1022;

BB0_209:
	add.f64 	%fd1660, %fd1833, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1661, %fd1660;
	add.f64 	%fd1602, %fd1833, 0dBFF0000000000000;
	mul.rn.f64 	%fd1662, %fd1602, %fd1661;
	add.f64 	%fd1650, %fd1662, %fd1662;
	mul.rn.f64 	%fd1598, %fd1650, %fd1650;
	mov.f64 	%fd1577, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1579, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1576, %fd1577, %fd1598, %fd1579;
	// inline asm
	mov.f64 	%fd1583, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1580, %fd1576, %fd1598, %fd1583;
	// inline asm
	mov.f64 	%fd1587, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1584, %fd1580, %fd1598, %fd1587;
	// inline asm
	mov.f64 	%fd1591, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1588, %fd1584, %fd1598, %fd1591;
	// inline asm
	mov.f64 	%fd1595, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1592, %fd1588, %fd1598, %fd1595;
	// inline asm
	mov.f64 	%fd1599, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1596, %fd1592, %fd1598, %fd1599;
	// inline asm
	mul.rn.f64 	%fd1663, %fd1596, %fd1598;
	sub.f64 	%fd1664, %fd1602, %fd1650;
	mul.rn.f64 	%fd1603, %fd1561, %fd1664;
	neg.f64 	%fd1601, %fd1650;
	// inline asm
	fma.rn.f64 	%fd1600, %fd1601, %fd1602, %fd1603;
	// inline asm
	mul.rn.f64 	%fd1646, %fd1661, %fd1600;
	add.f64 	%fd1666, %fd1663, 0d3FB5555555555555;
	mov.f64 	%fd1667, 0d3FB5555555555555;
	sub.f64 	%fd1668, %fd1667, %fd1666;
	add.f64 	%fd1669, %fd1663, %fd1668;
	add.f64 	%fd1670, %fd1669, 0d0000000000000000;
	add.f64 	%fd1671, %fd1670, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1613, %fd1666, %fd1671;
	sub.f64 	%fd1672, %fd1666, %fd1613;
	add.f64 	%fd1617, %fd1671, %fd1672;
	mul.rn.f64 	%fd1673, %fd1613, %fd1650;
	neg.f64 	%fd1607, %fd1673;
	// inline asm
	fma.rn.f64 	%fd1604, %fd1613, %fd1650, %fd1607;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1608, %fd1617, %fd1646, %fd1604;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1612, %fd1613, %fd1646, %fd1608;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1616, %fd1617, %fd1650, %fd1612;
	// inline asm
	add.f64 	%fd1629, %fd1673, %fd1616;
	sub.f64 	%fd1674, %fd1673, %fd1629;
	add.f64 	%fd1633, %fd1616, %fd1674;
	mul.rn.f64 	%fd1675, %fd1629, %fd1650;
	neg.f64 	%fd1623, %fd1675;
	// inline asm
	fma.rn.f64 	%fd1620, %fd1629, %fd1650, %fd1623;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1624, %fd1633, %fd1646, %fd1620;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1628, %fd1629, %fd1646, %fd1624;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1632, %fd1633, %fd1650, %fd1628;
	// inline asm
	add.f64 	%fd1645, %fd1675, %fd1632;
	sub.f64 	%fd1676, %fd1675, %fd1645;
	add.f64 	%fd1649, %fd1632, %fd1676;
	mul.rn.f64 	%fd1677, %fd1645, %fd1650;
	neg.f64 	%fd1639, %fd1677;
	// inline asm
	fma.rn.f64 	%fd1636, %fd1645, %fd1650, %fd1639;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1640, %fd1649, %fd1646, %fd1636;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1644, %fd1645, %fd1646, %fd1640;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1648, %fd1649, %fd1650, %fd1644;
	// inline asm
	add.f64 	%fd1678, %fd1677, %fd1648;
	sub.f64 	%fd1679, %fd1677, %fd1678;
	add.f64 	%fd1680, %fd1648, %fd1679;
	add.f64 	%fd1681, %fd1650, %fd1678;
	sub.f64 	%fd1682, %fd1650, %fd1681;
	add.f64 	%fd1683, %fd1678, %fd1682;
	add.f64 	%fd1684, %fd1680, %fd1683;
	add.f64 	%fd1685, %fd1646, %fd1684;
	add.f64 	%fd1686, %fd1681, %fd1685;
	sub.f64 	%fd1687, %fd1681, %fd1686;
	add.f64 	%fd1688, %fd1685, %fd1687;
	cvt.rn.f64.s32	%fd1689, %r358;
	mov.f64 	%fd1690, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1691, %fd1689, %fd1690;
	mov.f64 	%fd1692, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1693, %fd1689, %fd1692;
	add.f64 	%fd1694, %fd1691, %fd1686;
	sub.f64 	%fd1695, %fd1691, %fd1694;
	add.f64 	%fd1696, %fd1686, %fd1695;
	add.f64 	%fd1697, %fd1688, %fd1696;
	add.f64 	%fd1698, %fd1693, %fd1697;
	add.f64 	%fd1653, %fd1694, %fd1698;
	sub.f64 	%fd1699, %fd1694, %fd1653;
	add.f64 	%fd1657, %fd1698, %fd1699;
	mul.rn.f64 	%fd1700, %fd1653, %fd1557;
	neg.f64 	%fd1655, %fd1700;
	// inline asm
	fma.rn.f64 	%fd1652, %fd1653, %fd1557, %fd1655;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1656, %fd1657, %fd1557, %fd1652;
	// inline asm
	add.f64 	%fd234, %fd1700, %fd1656;
	sub.f64 	%fd1701, %fd1700, %fd234;
	add.f64 	%fd235, %fd1656, %fd1701;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd234;
	}
	mov.b32 	 %f11, %r140;
	abs.f32 	%f12, %f11;
	setp.lt.f32	%p171, %f12, 0f40874911;
	@%p171 bra 	BB0_211;
	bra.uni 	BB0_210;

BB0_211:
	mov.f64 	%fd1705, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1706, %fd234, %fd1705;
	mov.f64 	%fd1707, 0d4338000000000000;
	add.rn.f64 	%fd1708, %fd1706, %fd1707;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd1708;
	}
	mov.f64 	%fd1709, 0dC338000000000000;
	add.rn.f64 	%fd1710, %fd1708, %fd1709;
	mov.f64 	%fd1711, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1712, %fd1710, %fd1711, %fd234;
	mov.f64 	%fd1713, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1714, %fd1710, %fd1713, %fd1712;
	mov.f64 	%fd1715, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1716, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1717, %fd1716, %fd1714, %fd1715;
	mov.f64 	%fd1718, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1719, %fd1717, %fd1714, %fd1718;
	mov.f64 	%fd1720, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1721, %fd1719, %fd1714, %fd1720;
	mov.f64 	%fd1722, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1723, %fd1721, %fd1714, %fd1722;
	mov.f64 	%fd1724, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1725, %fd1723, %fd1714, %fd1724;
	mov.f64 	%fd1726, 0d3F81111111122322;
	fma.rn.f64 	%fd1727, %fd1725, %fd1714, %fd1726;
	mov.f64 	%fd1728, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1729, %fd1727, %fd1714, %fd1728;
	mov.f64 	%fd1730, 0d3FC5555555555511;
	fma.rn.f64 	%fd1731, %fd1729, %fd1714, %fd1730;
	mov.f64 	%fd1732, 0d3FE000000000000B;
	fma.rn.f64 	%fd1733, %fd1731, %fd1714, %fd1732;
	mov.f64 	%fd1734, 0d3FF0000000000000;
	fma.rn.f64 	%fd1735, %fd1733, %fd1714, %fd1734;
	fma.rn.f64 	%fd1834, %fd1735, %fd1714, %fd1734;
	abs.s32 	%r302, %r141;
	setp.lt.s32	%p174, %r302, 1023;
	@%p174 bra 	BB0_213;
	bra.uni 	BB0_212;

BB0_213:
	shl.b32 	%r308, %r141, 20;
	add.s32 	%r359, %r308, 1072693248;
	bra.uni 	BB0_214;

BB0_210:
	setp.lt.s32	%p172, %r140, 0;
	selp.f64	%fd1702, 0d0000000000000000, 0d7FF0000000000000, %p172;
	abs.f64 	%fd1703, %fd234;
	setp.gtu.f64	%p173, %fd1703, 0d7FF0000000000000;
	add.f64 	%fd1704, %fd234, %fd234;
	selp.f64	%fd1837, %fd1704, %fd1702, %p173;
	bra.uni 	BB0_215;

BB0_212:
	add.s32 	%r303, %r141, 2046;
	shl.b32 	%r304, %r303, 19;
	and.b32  	%r305, %r304, -1048576;
	shl.b32 	%r306, %r303, 20;
	sub.s32 	%r359, %r306, %r305;
	mov.u32 	%r307, 0;
	mov.b64 	%fd1736, {%r307, %r305};
	mul.f64 	%fd1834, %fd1834, %fd1736;

BB0_214:
	mov.u32 	%r309, 0;
	mov.b64 	%fd1737, {%r309, %r359};
	mul.f64 	%fd1837, %fd1834, %fd1737;

BB0_215:
	abs.f64 	%fd1738, %fd1837;
	setp.eq.f64	%p175, %fd1738, 0d7FF0000000000000;
	@%p175 bra 	BB0_217;

	// inline asm
	fma.rn.f64 	%fd1837, %fd1837, %fd235, %fd1837;
	// inline asm

BB0_217:
	setp.neu.f64	%p176, %fd230, 0d3FF0000000000000;
	or.pred  	%p178, %p167, %p176;
	@%p178 bra 	BB0_224;

	mov.b64 	 %rd59, %fd1837;
	xor.b64  	%rd60, %rd59, -9223372036854775808;
	mov.b64 	 %fd1837, %rd60;

BB0_224:
	mul.f64 	%fd1838, %fd1831, %fd1837;

BB0_225:
	ld.param.u64 	%rd67, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0];
	add.f64 	%fd1748, %fd190, %fd1838;
	sub.f64 	%fd1749, %fd1748, %fd1817;
	add.f64 	%fd1750, %fd148, %fd1749;
	add.f64 	%fd1751, %fd1779, %fd1750;
	add.s64 	%rd64, %rd67, %rd53;
	st.global.f64 	[%rd64], %fd1751;
	ret;
}


  